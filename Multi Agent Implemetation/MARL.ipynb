{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MARL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUGpioJIO1kD",
        "outputId": "521aa847-8b33-4098-e0e2-2a05816f9500"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\ashan\\anaconda3\\lib\\site-packages (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\ashan\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\ashan\\appdata\\roaming\\python\\python38\\site-packages (from torch) (1.19.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS0JTLDgO1kN"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBzhndhcO1kP"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQe9pG05O1kQ",
        "outputId": "e81298bc-0fd1-417e-eda0-c62ee700cac1"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLJQ3SSO1kR",
        "outputId": "62674ef6-bdb5-4c46-b58d-2edfac039051"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.33 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,680.99 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNAorWVZO1kS"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roCoUKVUO1kS"
      },
      "source": [
        "np.save('1e-6_1e-6_cooporation_shorfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceUS1YpOO1kS",
        "outputId": "ed59d600-5efe-411c-8e0c-610e1c08df99"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HonrFUgQO1kT"
      },
      "source": [
        "np.save('1e-6_1e-6_competition_trajectory_1500.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gsVuLWkO1kT"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6AT8A4yO1kU",
        "outputId": "44e3aaaa-6e56-43bb-9830-379400994ab8"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBEmKIOEO1kU",
        "outputId": "ec1f61f2-d998-48dc-e4a2-1b33b7ed360a"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OCS2oSkO1kU",
        "outputId": "651eefe5-2380-4ae4-e7e2-7215389820ac"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $nan \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $nan \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ4nnwgqO1kV"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyKb7NExO1kV"
      },
      "source": [
        "np.save('1e-6_shortfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFKyYsdDO1kV",
        "outputId": "610e64bc-b756-4e95-fbf2-38e74ccd60a2"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.778152 1.      ]\n",
            "[0.627577 1.      ]\n",
            "[0.4687 1.    ]\n",
            "[0.327324 1.      ]\n",
            "[0.219856 1.      ]\n",
            "[0.146201 1.      ]\n",
            "[0.101884 1.      ]\n",
            "[0.071515 1.      ]\n",
            "[0.049697 1.      ]\n",
            "[0.036779 1.      ]\n",
            "[0.027186 1.      ]\n",
            "[0.021121 1.      ]\n",
            "[0.015205 1.      ]\n",
            "[0.011104 1.      ]\n",
            "[0.007776 1.      ]\n",
            "[0.00544 1.     ]\n",
            "[0.003729 1.      ]\n",
            "[0.002632 1.      ]\n",
            "[0.001907 1.      ]\n",
            "[0.001427 1.      ]\n",
            "[0.001078 1.      ]\n",
            "[7.81e-04 1.00e+00]\n",
            "[5.87e-04 1.00e+00]\n",
            "[4.36e-04 1.00e+00]\n",
            "[3.4e-04 1.0e+00]\n",
            "[2.6e-04 1.0e+00]\n",
            "[1.92e-04 1.00e+00]\n",
            "[1.33e-04 1.00e+00]\n",
            "[9.7e-05 1.0e+00]\n",
            "[6.8e-05 1.0e+00]\n",
            "[4.6e-05 1.0e+00]\n",
            "[3.e-05 1.e+00]\n",
            "[2.e-05 1.e+00]\n",
            "[1.3e-05 1.0e+00]\n",
            "[9.e-06 1.e+00]\n",
            "[6.e-06 1.e+00]\n",
            "[4.e-06 1.e+00]\n",
            "[3.e-06 1.e+00]\n",
            "[2.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[0. 1.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbW_geMoO1kW"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufhY5_zO1kX",
        "outputId": "feaf796c-2f00-4bb7-ce20-8501a6be8d1e"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqNNXtbVO1kY",
        "outputId": "59a76602-138e-4aa4-d582-44025cb0c6d6"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>300,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>700,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6uqX9JPO1kZ",
        "outputId": "4e86d051-11ac-4189-f136-7f50c201b4a3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $705,887.29\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,665,016.69\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $768,639.85\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,793,241.57\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $749,953.03\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $1,771,843.57\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $283,857.44\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $694,621.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $238,277.70\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $423,662.34\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $425,146.37\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $561,076.02\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $419,305.60\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $508,430.64\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $415,315.80\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $496,617.05\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $603,856.39 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $1,298,712.22 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5cGGnXYO1kZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mkw8wMKO1kZ"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD2EGgptO1ka"
      },
      "source": [
        "np.save('1e-6_shortfall_list 0.3M.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFqt6jY3O1ka",
        "outputId": "0fa93c1a-32c3-41d5-83e1-fb22c137d0c2"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.         0.65632429]\n",
            "[0.         0.45492857]\n",
            "[0.         0.33422571]\n",
            "[0.      0.25539]\n",
            "[0.         0.20264286]\n",
            "[0.         0.14878714]\n",
            "[0.         0.10398857]\n",
            "[0.     0.0749]\n",
            "[0.         0.05252143]\n",
            "[0.         0.03660143]\n",
            "[0.         0.02446571]\n",
            "[0.      0.01732]\n",
            "[0.         0.01194286]\n",
            "[0.         0.00820429]\n",
            "[0.         0.00562286]\n",
            "[0.         0.00389857]\n",
            "[0.         0.00270286]\n",
            "[0.      0.00176]\n",
            "[0.         0.00113857]\n",
            "[0.         0.00077714]\n",
            "[0.         0.00056571]\n",
            "[0.         0.00039143]\n",
            "[0.         0.00028857]\n",
            "[0.         0.00021143]\n",
            "[0.      0.00015]\n",
            "[0.         0.00010857]\n",
            "[0.00000000e+00 7.57142857e-05]\n",
            "[0.00000000e+00 5.42857143e-05]\n",
            "[0.00000000e+00 4.14285714e-05]\n",
            "[0.00000000e+00 3.28571429e-05]\n",
            "[0.00000000e+00 2.57142857e-05]\n",
            "[0.e+00 2.e-05]\n",
            "[0.00000000e+00 1.57142857e-05]\n",
            "[0.00000000e+00 1.28571429e-05]\n",
            "[0.e+00 1.e-05]\n",
            "[0.00000000e+00 7.14285714e-06]\n",
            "[0.00000000e+00 5.71428571e-06]\n",
            "[0.00000000e+00 4.28571429e-06]\n",
            "[0.00000000e+00 2.85714286e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $414,998.47\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $502,074.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVKDPYhGO1ka"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l7MF7XNO1ka",
        "outputId": "36825356-76c1-4054-a66c-0c306e0074da"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LSTbf0OO1kb",
        "outputId": "5e683d1f-b885-4d01-8c81-9e10bdc8c3f5"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>700,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>300,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSfV1_v_O1kb",
        "outputId": "8a0e1cb8-75e6-417f-d8fd-1005c2d3e2a5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $1,636,719.61\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $708,470.86\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,793,749.54\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $768,749.40\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,793,750.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $768,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $1,793,414.77\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $768,695.70\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $1,777,672.76\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $765,635.58\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $1,047,445.39\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $487,752.08\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $1,416,671.63\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $301,228.20\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $1,444,264.43\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $265,269.88\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $1,442,974.50\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $289,855.98\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $1,446,263.20\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $275,372.15\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $1,449,751.19\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $288,511.11\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $1,444,305.59\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $265,479.80\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $1,440,052.19\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $259,734.99\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $1,532,848.83 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $477,961.98 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmyV3F6IO1kb"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hc9Bi5CO1kb"
      },
      "source": [
        "np.save('1e-6_shortfall_list 0.7M.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ZiC4ZkO1kc",
        "outputId": "c501d64e-24ce-40a5-c8f6-8e10a0090d9e"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.         0.65632333]\n",
            "[0.      0.45493]\n",
            "[0.         0.33422667]\n",
            "[0.      0.25539]\n",
            "[0.         0.20264333]\n",
            "[0.         0.14878667]\n",
            "[0.      0.10399]\n",
            "[0.     0.0749]\n",
            "[0.      0.05252]\n",
            "[0.     0.0366]\n",
            "[0.         0.02446333]\n",
            "[0.         0.01731667]\n",
            "[0.      0.01194]\n",
            "[0.         0.00820333]\n",
            "[0.         0.00562333]\n",
            "[0.     0.0039]\n",
            "[0.         0.00270333]\n",
            "[0.      0.00176]\n",
            "[0.      0.00114]\n",
            "[0.         0.00077667]\n",
            "[0.         0.00056333]\n",
            "[0.      0.00039]\n",
            "[0.         0.00028667]\n",
            "[0.      0.00021]\n",
            "[0.      0.00015]\n",
            "[0.         0.00010667]\n",
            "[0.00000000e+00 7.33333333e-05]\n",
            "[0.00000000e+00 5.33333333e-05]\n",
            "[0.e+00 4.e-05]\n",
            "[0.e+00 3.e-05]\n",
            "[0.00000000e+00 2.33333333e-05]\n",
            "[0.00000000e+00 1.66666667e-05]\n",
            "[0.00000000e+00 1.33333333e-05]\n",
            "[0.e+00 1.e-05]\n",
            "[0.00000000e+00 6.66666667e-06]\n",
            "[0.00000000e+00 6.66666667e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "[0.00000000e+00 3.33333333e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $1,439,734.86\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $262,064.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJYN7RmO1kc"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPJX2rwbO1kc",
        "outputId": "8fd9aca2-53e1-4dd7-adaa-8a9ab6172046"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'financial_params' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0787c3e3c320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinancial_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'financial_params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o24uBXddO1kc",
        "outputId": "fc578486-2c48-4c7b-bb63-95fd07bd4b0e"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvqINFF4O1kd",
        "outputId": "54466289-47aa-4a5a-ca87-c37fe4e742e3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $nan \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $nan \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wQ9HtcCO1kd"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv2sW_PQO1kd"
      },
      "source": [
        "np.save('1e-6_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXMcZFheO1kd",
        "outputId": "68310170-0c0d-435f-c299-7cc5a33464d2"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.778152 1.      ]\n",
            "[0.627577 1.      ]\n",
            "[0.4687 1.    ]\n",
            "[0.327324 1.      ]\n",
            "[0.219856 1.      ]\n",
            "[0.146201 1.      ]\n",
            "[0.101884 1.      ]\n",
            "[0.071515 1.      ]\n",
            "[0.049697 1.      ]\n",
            "[0.036779 1.      ]\n",
            "[0.027186 1.      ]\n",
            "[0.021121 1.      ]\n",
            "[0.015205 1.      ]\n",
            "[0.011104 1.      ]\n",
            "[0.007776 1.      ]\n",
            "[0.00544 1.     ]\n",
            "[0.003729 1.      ]\n",
            "[0.002632 1.      ]\n",
            "[0.001907 1.      ]\n",
            "[0.001427 1.      ]\n",
            "[0.001078 1.      ]\n",
            "[7.81e-04 1.00e+00]\n",
            "[5.87e-04 1.00e+00]\n",
            "[4.36e-04 1.00e+00]\n",
            "[3.4e-04 1.0e+00]\n",
            "[2.6e-04 1.0e+00]\n",
            "[1.92e-04 1.00e+00]\n",
            "[1.33e-04 1.00e+00]\n",
            "[9.7e-05 1.0e+00]\n",
            "[6.8e-05 1.0e+00]\n",
            "[4.6e-05 1.0e+00]\n",
            "[3.e-05 1.e+00]\n",
            "[2.e-05 1.e+00]\n",
            "[1.3e-05 1.0e+00]\n",
            "[9.e-06 1.e+00]\n",
            "[6.e-06 1.e+00]\n",
            "[4.e-06 1.e+00]\n",
            "[3.e-06 1.e+00]\n",
            "[2.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[0. 1.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3p5z4fO1ke"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-HsX2guO1ke",
        "outputId": "ef71d303-7435-48ee-b422-ec0b4612ddf3"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF1C_bH3O1ke",
        "outputId": "1b84d99a-c350-4e3b-9b07-acd7d10b8677"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>0.0001</td>   <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>       <td>1,000,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5TcM61PO1ke",
        "outputId": "0b1d9b17-4f58-47f4-85fd-e8beced07e47"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $0.01\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $0.00 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $2,562,500.00 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1FxxK5sO1kf"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5S5upFO1kf"
      },
      "source": [
        "np.save('1e-9_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZtseR5HO1kf",
        "outputId": "2df2044a-4f33-4be1-c550-ff343829e5f1"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[1.       0.635651]\n",
            "[1.      0.42943]\n",
            "[1.       0.309079]\n",
            "[1.       0.232251]\n",
            "[1.       0.181777]\n",
            "[1.     0.1318]\n",
            "[1.       0.091089]\n",
            "[1.       0.065006]\n",
            "[1.       0.045217]\n",
            "[1.       0.031294]\n",
            "[1.       0.020791]\n",
            "[1.       0.014646]\n",
            "[1.       0.010056]\n",
            "[1.       0.006883]\n",
            "[1.       0.004702]\n",
            "[1.       0.003252]\n",
            "[1.      0.00225]\n",
            "[1.       0.001463]\n",
            "[1.00e+00 9.45e-04]\n",
            "[1.00e+00 6.44e-04]\n",
            "[1.00e+00 4.68e-04]\n",
            "[1.00e+00 3.24e-04]\n",
            "[1.00e+00 2.39e-04]\n",
            "[1.00e+00 1.75e-04]\n",
            "[1.00e+00 1.24e-04]\n",
            "[1.0e+00 8.9e-05]\n",
            "[1.0e+00 6.2e-05]\n",
            "[1.0e+00 4.5e-05]\n",
            "[1.0e+00 3.4e-05]\n",
            "[1.0e+00 2.7e-05]\n",
            "[1.e+00 2.e-06]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "[1. 0.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvggJwLpO1kg"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iovlIJ6O1kg",
        "outputId": "f5522cb9-0742-434b-bc50-45bd5d2bbb26"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT94uz6kO1kg",
        "outputId": "fe599d20-f7de-47ef-f8c3-1813447bd044"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDlA0fsXO1kh",
        "outputId": "8c03b194-6680-4691-983a-df2aa44e4e12"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.33 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,680.99 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gldpNOlEO1kh"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIyo7Y3O1kh"
      },
      "source": [
        "np.save('1e-4_le-9_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_lEn-2O1kh",
        "outputId": "0d5c5beb-5e99-4a1b-a8c6-18961d0a8966"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_FFXfLO1ki"
      },
      "source": [
        "np.save('1e-4_le-9_trajectory.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voegn0WyO1ki"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7CAgAWuO1ki",
        "outputId": "7d77c859-b4d5-4288-d5d0-3dedac1094b2"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXfhYOGzO1ki",
        "outputId": "00a81ba7-48ec-4d92-b664-35555960fce2"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ln59YDAO1kj",
        "outputId": "0c69c0a8-ce7f-466c-dd19-63a1d604f741"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.33 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,680.99 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfloNsJbO1kj"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhU8L7EEO1kj"
      },
      "source": [
        "np.save('1e-6_le-6_competition_shortfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTTTUHy0O1kk",
        "outputId": "1f2c0b73-3edd-4c0d-af97-ca9cab34a02b"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OLdiLzCO1kk"
      },
      "source": [
        "np.save('1e-6_trajectory_fixed-competitor.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTXYXgXXO1kk"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxsoUEUMO1kk",
        "outputId": "2b7593d0-6912-4d3f-c5fd-b0e1958f14da"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih3G_doIO1kl",
        "outputId": "cc082d8b-3e97-4f42-a86f-4ead9c9377ff"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc6yJlSXO1kl",
        "outputId": "08197b90-bbc5-4047-d8d4-41a332bc8b8d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1500\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1500]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1500]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1500]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1500]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1500]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1500]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1500]\tAverage Shortfall for Agent1: $958,446.35\n",
            "Episode [400/1500]\tAverage Shortfall for Agent2: $996,403.21\n",
            "Episode [500/1500]\tAverage Shortfall for Agent1: $321,537.18\n",
            "Episode [500/1500]\tAverage Shortfall for Agent2: $321,944.71\n",
            "Episode [600/1500]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1500]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1500]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1500]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1500]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1500]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1500]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1500]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1500]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1500]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1500]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1500]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1500]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1500]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1500]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1500]\tAverage Shortfall for Agent2: $292,937.04\n",
            "Episode [1400/1500]\tAverage Shortfall for Agent1: $330,056.55\n",
            "Episode [1400/1500]\tAverage Shortfall for Agent2: $333,447.92\n",
            "Episode [1500/1500]\tAverage Shortfall for Agent1: $340,174.15\n",
            "Episode [1500/1500]\tAverage Shortfall for Agent2: $346,873.58\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $546,753.60 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $550,344.96 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEB81WNUO1kl"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbzjO5S9O1km"
      },
      "source": [
        "np.save('1e-6_le-6_competition_shortfall_list_1500.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rUgQzLzO1km",
        "outputId": "5f40c881-563d-4299-85ac-b28c804840df"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.769192 0.70972 ]\n",
            "[0.591748 0.51279 ]\n",
            "[0.450466 0.390248]\n",
            "[0.326848 0.284012]\n",
            "[0.24921  0.197246]\n",
            "[0.190718 0.142906]\n",
            "[0.140292 0.097372]\n",
            "[0.105616 0.06362 ]\n",
            "[0.07375  0.041506]\n",
            "[0.048    0.026404]\n",
            "[0.029694 0.016936]\n",
            "[0.019016 0.011058]\n",
            "[0.011524 0.0077  ]\n",
            "[0.007654 0.00507 ]\n",
            "[0.004818 0.003454]\n",
            "[0.002948 0.002304]\n",
            "[0.00176  0.001582]\n",
            "[0.00102  0.001078]\n",
            "[0.00064  0.000704]\n",
            "[0.000388 0.000446]\n",
            "[0.000252 0.000288]\n",
            "[0.000156 0.000186]\n",
            "[9.40e-05 1.28e-04]\n",
            "[5.6e-05 9.0e-05]\n",
            "[3.4e-05 6.6e-05]\n",
            "[2.e-05 5.e-05]\n",
            "[1.2e-05 3.6e-05]\n",
            "[8.0e-06 2.8e-05]\n",
            "[6.e-06 2.e-05]\n",
            "[4.0e-06 1.4e-05]\n",
            "[2.e-06 1.e-05]\n",
            "[2.e-06 8.e-06]\n",
            "[2.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1500/1500]\tAverage Shortfall for Agent1: $342,143.56\n",
            "Episode [1500/1500]\tAverage Shortfall for Agent2: $348,499.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3I8BHNMO1km"
      },
      "source": [
        "np.save('1e-6_le-6_competition_trajectory_1500.npy.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp7R8-0vO1km"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kdxV0zBO1km",
        "outputId": "f4852a7a-52b3-40d1-b91f-03b24a70b5eb"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWFENX0KO1kn",
        "outputId": "d7763463-36b2-486e-c396-514484d73236"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOAlDb83O1kn",
        "outputId": "ef1e14a2-8044-45f9-e029-875528024dd8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $1,177,354.62\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,183,580.64\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $1,257,995.97\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $1,272,524.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $695,096.68\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $801,598.95\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $329,916.66\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $337,108.06\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $632,122.09 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $641,731.72 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi5cWVFBO1kn"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcWcLGnWO1ko"
      },
      "source": [
        "np.save('1e-6_le-6_corporatition_shortfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTUj8ViRO1kp",
        "outputId": "7df88cef-7e22-4b9f-d80d-6d835293c481"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPdfPFPMO1kq"
      },
      "source": [
        "np.save('1e-6_trajectory_fixed-corporation.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIR0x9SRO1kq"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDLAmklAO1kq",
        "outputId": "51e74e24-eb0c-4731-d825-3dbaab2578be"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyZ3R2uUO1kr",
        "outputId": "e184c558-3aea-4d2e-aef4-9f13e05c8d93"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07IKlp09O1kr",
        "outputId": "cba95b3e-f101-40bb-bc5d-b0984ad7af11"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $nan \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $nan \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0493254O1kr"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WiCEfJO1kr"
      },
      "source": [
        "np.save('1e-6_shortfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V00J5hbzO1ks",
        "outputId": "fd71fabb-f0fb-40be-9757-63261db58bd9"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.778152 1.      ]\n",
            "[0.627577 1.      ]\n",
            "[0.4687 1.    ]\n",
            "[0.327324 1.      ]\n",
            "[0.219856 1.      ]\n",
            "[0.146201 1.      ]\n",
            "[0.101884 1.      ]\n",
            "[0.071515 1.      ]\n",
            "[0.049697 1.      ]\n",
            "[0.036779 1.      ]\n",
            "[0.027186 1.      ]\n",
            "[0.021121 1.      ]\n",
            "[0.015205 1.      ]\n",
            "[0.011104 1.      ]\n",
            "[0.007776 1.      ]\n",
            "[0.00544 1.     ]\n",
            "[0.003729 1.      ]\n",
            "[0.002632 1.      ]\n",
            "[0.001907 1.      ]\n",
            "[0.001427 1.      ]\n",
            "[0.001078 1.      ]\n",
            "[7.81e-04 1.00e+00]\n",
            "[5.87e-04 1.00e+00]\n",
            "[4.36e-04 1.00e+00]\n",
            "[3.4e-04 1.0e+00]\n",
            "[2.6e-04 1.0e+00]\n",
            "[1.92e-04 1.00e+00]\n",
            "[1.33e-04 1.00e+00]\n",
            "[9.7e-05 1.0e+00]\n",
            "[6.8e-05 1.0e+00]\n",
            "[4.6e-05 1.0e+00]\n",
            "[3.e-05 1.e+00]\n",
            "[2.e-05 1.e+00]\n",
            "[1.3e-05 1.0e+00]\n",
            "[9.e-06 1.e+00]\n",
            "[6.e-06 1.e+00]\n",
            "[4.e-06 1.e+00]\n",
            "[3.e-06 1.e+00]\n",
            "[2.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[0. 1.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifrZSoXTO1ks"
      },
      "source": [
        "np.save('1e-6_optimal.npy.npy',trajectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHaTePVPO1ks"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmgUVxE0O1ks"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D61p6OxO1ks"
      },
      "source": [
        "import utils\n",
        "import ddpg_agent\n",
        "import model \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.rc('xtick',labelsize=14)\n",
        "plt.rc('ytick',labelsize=14)\n",
        "plt.rc('legend',fontsize = 14)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}