{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/17/ee73e3011b9f62919eb2991ed4c216b90285469c6d0b11c1cda6538819b1/torch-1.8.1-cp37-none-macosx_10_9_x86_64.whl (119.5MB)\n",
      "\u001b[K     |████████████████████████████████| 119.5MB 16.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions (from torch)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Users/venukorada/anaconda3/lib/python3.7/site-packages (from torch) (1.16.4)\n",
      "Installing collected packages: typing-extensions, torch\n",
      "Successfully installed torch-1.8.1 typing-extensions-3.7.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th> <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $579,313.33 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $582,680.99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_1e-6_cooporation_shorfall_list.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.761694 0.656324]\n",
      "[0.603648 0.454928]\n",
      "[0.44365  0.334226]\n",
      "[0.305346 0.25539 ]\n",
      "[0.20247  0.202642]\n",
      "[0.13316  0.148788]\n",
      "[0.09197 0.10399]\n",
      "[0.064072 0.074902]\n",
      "[0.044238 0.052522]\n",
      "[0.03257  0.036602]\n",
      "[0.02397  0.024466]\n",
      "[0.018556 0.01732 ]\n",
      "[0.013314 0.011942]\n",
      "[0.009696 0.008204]\n",
      "[0.006774 0.005622]\n",
      "[0.004728 0.003898]\n",
      "[0.003236 0.002704]\n",
      "[0.00228  0.001762]\n",
      "[0.00165 0.00114]\n",
      "[0.001234 0.000778]\n",
      "[0.000932 0.000566]\n",
      "[0.000674 0.000392]\n",
      "[0.000506 0.00029 ]\n",
      "[0.000376 0.000212]\n",
      "[0.000294 0.00015 ]\n",
      "[0.000224 0.000108]\n",
      "[1.66e-04 7.40e-05]\n",
      "[1.14e-04 5.40e-05]\n",
      "[8.2e-05 4.2e-05]\n",
      "[5.8e-05 3.4e-05]\n",
      "[4.0e-05 2.8e-05]\n",
      "[2.6e-05 2.2e-05]\n",
      "[1.8e-05 1.8e-05]\n",
      "[1.2e-05 1.4e-05]\n",
      "[8.e-06 1.e-05]\n",
      "[6.e-06 8.e-06]\n",
      "[4.e-06 6.e-06]\n",
      "[2.e-06 4.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_1e-6_competition_trajectory_1500.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $nan \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_shortfall_list.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.778152 1.      ]\n",
      "[0.627577 1.      ]\n",
      "[0.4687 1.    ]\n",
      "[0.327324 1.      ]\n",
      "[0.219856 1.      ]\n",
      "[0.146201 1.      ]\n",
      "[0.101884 1.      ]\n",
      "[0.071515 1.      ]\n",
      "[0.049697 1.      ]\n",
      "[0.036779 1.      ]\n",
      "[0.027186 1.      ]\n",
      "[0.021121 1.      ]\n",
      "[0.015205 1.      ]\n",
      "[0.011104 1.      ]\n",
      "[0.007776 1.      ]\n",
      "[0.00544 1.     ]\n",
      "[0.003729 1.      ]\n",
      "[0.002632 1.      ]\n",
      "[0.001907 1.      ]\n",
      "[0.001427 1.      ]\n",
      "[0.001078 1.      ]\n",
      "[7.81e-04 1.00e+00]\n",
      "[5.87e-04 1.00e+00]\n",
      "[4.36e-04 1.00e+00]\n",
      "[3.4e-04 1.0e+00]\n",
      "[2.6e-04 1.0e+00]\n",
      "[1.92e-04 1.00e+00]\n",
      "[1.33e-04 1.00e+00]\n",
      "[9.7e-05 1.0e+00]\n",
      "[6.8e-05 1.0e+00]\n",
      "[4.6e-05 1.0e+00]\n",
      "[3.e-05 1.e+00]\n",
      "[2.e-05 1.e+00]\n",
      "[1.3e-05 1.0e+00]\n",
      "[9.e-06 1.e+00]\n",
      "[6.e-06 1.e+00]\n",
      "[4.e-06 1.e+00]\n",
      "[3.e-06 1.e+00]\n",
      "[2.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[0. 1.]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>300,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>700,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $705,887.29\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $1,665,016.69\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $768,639.85\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $1,793,241.57\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $749,953.03\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $1,771,843.57\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $283,857.44\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $694,621.00\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $238,277.70\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $423,662.34\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $425,146.37\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $561,076.02\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $419,305.60\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $508,430.64\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $415,315.80\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $496,617.05\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $603,856.39 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $1,298,712.22 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_shortfall_list 0.3M.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.         0.65632429]\n",
      "[0.         0.45492857]\n",
      "[0.         0.33422571]\n",
      "[0.      0.25539]\n",
      "[0.         0.20264286]\n",
      "[0.         0.14878714]\n",
      "[0.         0.10398857]\n",
      "[0.     0.0749]\n",
      "[0.         0.05252143]\n",
      "[0.         0.03660143]\n",
      "[0.         0.02446571]\n",
      "[0.      0.01732]\n",
      "[0.         0.01194286]\n",
      "[0.         0.00820429]\n",
      "[0.         0.00562286]\n",
      "[0.         0.00389857]\n",
      "[0.         0.00270286]\n",
      "[0.      0.00176]\n",
      "[0.         0.00113857]\n",
      "[0.         0.00077714]\n",
      "[0.         0.00056571]\n",
      "[0.         0.00039143]\n",
      "[0.         0.00028857]\n",
      "[0.         0.00021143]\n",
      "[0.      0.00015]\n",
      "[0.         0.00010857]\n",
      "[0.00000000e+00 7.57142857e-05]\n",
      "[0.00000000e+00 5.42857143e-05]\n",
      "[0.00000000e+00 4.14285714e-05]\n",
      "[0.00000000e+00 3.28571429e-05]\n",
      "[0.00000000e+00 2.57142857e-05]\n",
      "[0.e+00 2.e-05]\n",
      "[0.00000000e+00 1.57142857e-05]\n",
      "[0.00000000e+00 1.28571429e-05]\n",
      "[0.e+00 1.e-05]\n",
      "[0.00000000e+00 7.14285714e-06]\n",
      "[0.00000000e+00 5.71428571e-06]\n",
      "[0.00000000e+00 4.28571429e-06]\n",
      "[0.00000000e+00 2.85714286e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "[0.00000000e+00 1.42857143e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $414,998.47\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $502,074.11\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>700,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>300,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $1,636,719.61\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $708,470.86\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $1,793,749.54\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $768,749.40\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $1,793,750.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $768,750.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $1,793,414.77\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $768,695.70\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $1,777,672.76\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $765,635.58\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $1,047,445.39\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $487,752.08\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $1,416,671.63\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $301,228.20\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $1,444,264.43\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $265,269.88\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $1,442,974.50\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $289,855.98\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $1,446,263.20\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $275,372.15\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $1,449,751.19\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $288,511.11\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $1,444,305.59\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $265,479.80\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $1,440,052.19\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $259,734.99\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $1,532,848.83 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $477,961.98 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_shortfall_list 0.7M.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.         0.65632333]\n",
      "[0.      0.45493]\n",
      "[0.         0.33422667]\n",
      "[0.      0.25539]\n",
      "[0.         0.20264333]\n",
      "[0.         0.14878667]\n",
      "[0.      0.10399]\n",
      "[0.     0.0749]\n",
      "[0.      0.05252]\n",
      "[0.     0.0366]\n",
      "[0.         0.02446333]\n",
      "[0.         0.01731667]\n",
      "[0.      0.01194]\n",
      "[0.         0.00820333]\n",
      "[0.         0.00562333]\n",
      "[0.     0.0039]\n",
      "[0.         0.00270333]\n",
      "[0.      0.00176]\n",
      "[0.      0.00114]\n",
      "[0.         0.00077667]\n",
      "[0.         0.00056333]\n",
      "[0.      0.00039]\n",
      "[0.         0.00028667]\n",
      "[0.      0.00021]\n",
      "[0.      0.00015]\n",
      "[0.         0.00010667]\n",
      "[0.00000000e+00 7.33333333e-05]\n",
      "[0.00000000e+00 5.33333333e-05]\n",
      "[0.e+00 4.e-05]\n",
      "[0.e+00 3.e-05]\n",
      "[0.00000000e+00 2.33333333e-05]\n",
      "[0.00000000e+00 1.66666667e-05]\n",
      "[0.00000000e+00 1.33333333e-05]\n",
      "[0.e+00 1.e-05]\n",
      "[0.00000000e+00 6.66666667e-06]\n",
      "[0.00000000e+00 6.66666667e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "[0.00000000e+00 3.33333333e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $1,439,734.86\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $262,064.29\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'financial_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0787c3e3c320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinancial_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'financial_params' is not defined"
     ]
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $nan \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_shortfall_optimal.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.778152 1.      ]\n",
      "[0.627577 1.      ]\n",
      "[0.4687 1.    ]\n",
      "[0.327324 1.      ]\n",
      "[0.219856 1.      ]\n",
      "[0.146201 1.      ]\n",
      "[0.101884 1.      ]\n",
      "[0.071515 1.      ]\n",
      "[0.049697 1.      ]\n",
      "[0.036779 1.      ]\n",
      "[0.027186 1.      ]\n",
      "[0.021121 1.      ]\n",
      "[0.015205 1.      ]\n",
      "[0.011104 1.      ]\n",
      "[0.007776 1.      ]\n",
      "[0.00544 1.     ]\n",
      "[0.003729 1.      ]\n",
      "[0.002632 1.      ]\n",
      "[0.001907 1.      ]\n",
      "[0.001427 1.      ]\n",
      "[0.001078 1.      ]\n",
      "[7.81e-04 1.00e+00]\n",
      "[5.87e-04 1.00e+00]\n",
      "[4.36e-04 1.00e+00]\n",
      "[3.4e-04 1.0e+00]\n",
      "[2.6e-04 1.0e+00]\n",
      "[1.92e-04 1.00e+00]\n",
      "[1.33e-04 1.00e+00]\n",
      "[9.7e-05 1.0e+00]\n",
      "[6.8e-05 1.0e+00]\n",
      "[4.6e-05 1.0e+00]\n",
      "[3.e-05 1.e+00]\n",
      "[2.e-05 1.e+00]\n",
      "[1.3e-05 1.0e+00]\n",
      "[9.e-06 1.e+00]\n",
      "[6.e-06 1.e+00]\n",
      "[4.e-06 1.e+00]\n",
      "[3.e-06 1.e+00]\n",
      "[2.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[0. 1.]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>0.0001</td>   <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>       <td>1,000,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>    <td>0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $0.01\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $0.00 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $2,562,500.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-9_shortfall_optimal.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[1.       0.635651]\n",
      "[1.      0.42943]\n",
      "[1.       0.309079]\n",
      "[1.       0.232251]\n",
      "[1.       0.181777]\n",
      "[1.     0.1318]\n",
      "[1.       0.091089]\n",
      "[1.       0.065006]\n",
      "[1.       0.045217]\n",
      "[1.       0.031294]\n",
      "[1.       0.020791]\n",
      "[1.       0.014646]\n",
      "[1.       0.010056]\n",
      "[1.       0.006883]\n",
      "[1.       0.004702]\n",
      "[1.       0.003252]\n",
      "[1.      0.00225]\n",
      "[1.       0.001463]\n",
      "[1.00e+00 9.45e-04]\n",
      "[1.00e+00 6.44e-04]\n",
      "[1.00e+00 4.68e-04]\n",
      "[1.00e+00 3.24e-04]\n",
      "[1.00e+00 2.39e-04]\n",
      "[1.00e+00 1.75e-04]\n",
      "[1.00e+00 1.24e-04]\n",
      "[1.0e+00 8.9e-05]\n",
      "[1.0e+00 6.2e-05]\n",
      "[1.0e+00 4.5e-05]\n",
      "[1.0e+00 3.4e-05]\n",
      "[1.0e+00 2.7e-05]\n",
      "[1.e+00 2.e-06]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $579,313.33 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $582,680.99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-4_le-9_shortfall_optimal.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.761694 0.656324]\n",
      "[0.603648 0.454928]\n",
      "[0.44365  0.334226]\n",
      "[0.305346 0.25539 ]\n",
      "[0.20247  0.202642]\n",
      "[0.13316  0.148788]\n",
      "[0.09197 0.10399]\n",
      "[0.064072 0.074902]\n",
      "[0.044238 0.052522]\n",
      "[0.03257  0.036602]\n",
      "[0.02397  0.024466]\n",
      "[0.018556 0.01732 ]\n",
      "[0.013314 0.011942]\n",
      "[0.009696 0.008204]\n",
      "[0.006774 0.005622]\n",
      "[0.004728 0.003898]\n",
      "[0.003236 0.002704]\n",
      "[0.00228  0.001762]\n",
      "[0.00165 0.00114]\n",
      "[0.001234 0.000778]\n",
      "[0.000932 0.000566]\n",
      "[0.000674 0.000392]\n",
      "[0.000506 0.00029 ]\n",
      "[0.000376 0.000212]\n",
      "[0.000294 0.00015 ]\n",
      "[0.000224 0.000108]\n",
      "[1.66e-04 7.40e-05]\n",
      "[1.14e-04 5.40e-05]\n",
      "[8.2e-05 4.2e-05]\n",
      "[5.8e-05 3.4e-05]\n",
      "[4.0e-05 2.8e-05]\n",
      "[2.6e-05 2.2e-05]\n",
      "[1.8e-05 1.8e-05]\n",
      "[1.2e-05 1.4e-05]\n",
      "[8.e-06 1.e-05]\n",
      "[6.e-06 8.e-06]\n",
      "[4.e-06 6.e-06]\n",
      "[2.e-06 4.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-4_le-9_trajectory.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.21\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $579,313.33 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $582,680.99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_le-6_competition_shortfall_list.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.761694 0.656324]\n",
      "[0.603648 0.454928]\n",
      "[0.44365  0.334226]\n",
      "[0.305346 0.25539 ]\n",
      "[0.20247  0.202642]\n",
      "[0.13316  0.148788]\n",
      "[0.09197 0.10399]\n",
      "[0.064072 0.074902]\n",
      "[0.044238 0.052522]\n",
      "[0.03257  0.036602]\n",
      "[0.02397  0.024466]\n",
      "[0.018556 0.01732 ]\n",
      "[0.013314 0.011942]\n",
      "[0.009696 0.008204]\n",
      "[0.006774 0.005622]\n",
      "[0.004728 0.003898]\n",
      "[0.003236 0.002704]\n",
      "[0.00228  0.001762]\n",
      "[0.00165 0.00114]\n",
      "[0.001234 0.000778]\n",
      "[0.000932 0.000566]\n",
      "[0.000674 0.000392]\n",
      "[0.000506 0.00029 ]\n",
      "[0.000376 0.000212]\n",
      "[0.000294 0.00015 ]\n",
      "[0.000224 0.000108]\n",
      "[1.66e-04 7.40e-05]\n",
      "[1.14e-04 5.40e-05]\n",
      "[8.2e-05 4.2e-05]\n",
      "[5.8e-05 3.4e-05]\n",
      "[4.0e-05 2.8e-05]\n",
      "[2.6e-05 2.2e-05]\n",
      "[1.8e-05 1.8e-05]\n",
      "[1.2e-05 1.4e-05]\n",
      "[8.e-06 1.e-05]\n",
      "[6.e-06 8.e-06]\n",
      "[4.e-06 6.e-06]\n",
      "[2.e-06 4.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_trajectory_fixed-competitor.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1500]\tAverage Shortfall for Agent1: $1,168,737.12\n",
      "Episode [100/1500]\tAverage Shortfall for Agent2: $1,182,497.04\n",
      "Episode [200/1500]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [200/1500]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [300/1500]\tAverage Shortfall for Agent1: $1,274,753.86\n",
      "Episode [300/1500]\tAverage Shortfall for Agent2: $1,278,818.43\n",
      "Episode [400/1500]\tAverage Shortfall for Agent1: $958,446.35\n",
      "Episode [400/1500]\tAverage Shortfall for Agent2: $996,403.21\n",
      "Episode [500/1500]\tAverage Shortfall for Agent1: $321,537.18\n",
      "Episode [500/1500]\tAverage Shortfall for Agent2: $321,944.71\n",
      "Episode [600/1500]\tAverage Shortfall for Agent1: $331,625.64\n",
      "Episode [600/1500]\tAverage Shortfall for Agent2: $328,738.83\n",
      "Episode [700/1500]\tAverage Shortfall for Agent1: $302,789.39\n",
      "Episode [700/1500]\tAverage Shortfall for Agent2: $296,596.55\n",
      "Episode [800/1500]\tAverage Shortfall for Agent1: $305,151.05\n",
      "Episode [800/1500]\tAverage Shortfall for Agent2: $301,542.19\n",
      "Episode [900/1500]\tAverage Shortfall for Agent1: $343,508.22\n",
      "Episode [900/1500]\tAverage Shortfall for Agent2: $342,052.92\n",
      "Episode [1000/1500]\tAverage Shortfall for Agent1: $318,731.56\n",
      "Episode [1000/1500]\tAverage Shortfall for Agent2: $317,495.71\n",
      "Episode [1100/1500]\tAverage Shortfall for Agent1: $329,135.85\n",
      "Episode [1100/1500]\tAverage Shortfall for Agent2: $333,255.71\n",
      "Episode [1200/1500]\tAverage Shortfall for Agent1: $300,993.44\n",
      "Episode [1200/1500]\tAverage Shortfall for Agent2: $301,320.57\n",
      "Episode [1300/1500]\tAverage Shortfall for Agent1: $294,413.69\n",
      "Episode [1300/1500]\tAverage Shortfall for Agent2: $292,937.04\n",
      "Episode [1400/1500]\tAverage Shortfall for Agent1: $330,056.55\n",
      "Episode [1400/1500]\tAverage Shortfall for Agent2: $333,447.92\n",
      "Episode [1500/1500]\tAverage Shortfall for Agent1: $340,174.15\n",
      "Episode [1500/1500]\tAverage Shortfall for Agent2: $346,873.58\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $546,753.60 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $550,344.96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1500\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_le-6_competition_shortfall_list_1500.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.769192 0.70972 ]\n",
      "[0.591748 0.51279 ]\n",
      "[0.450466 0.390248]\n",
      "[0.326848 0.284012]\n",
      "[0.24921  0.197246]\n",
      "[0.190718 0.142906]\n",
      "[0.140292 0.097372]\n",
      "[0.105616 0.06362 ]\n",
      "[0.07375  0.041506]\n",
      "[0.048    0.026404]\n",
      "[0.029694 0.016936]\n",
      "[0.019016 0.011058]\n",
      "[0.011524 0.0077  ]\n",
      "[0.007654 0.00507 ]\n",
      "[0.004818 0.003454]\n",
      "[0.002948 0.002304]\n",
      "[0.00176  0.001582]\n",
      "[0.00102  0.001078]\n",
      "[0.00064  0.000704]\n",
      "[0.000388 0.000446]\n",
      "[0.000252 0.000288]\n",
      "[0.000156 0.000186]\n",
      "[9.40e-05 1.28e-04]\n",
      "[5.6e-05 9.0e-05]\n",
      "[3.4e-05 6.6e-05]\n",
      "[2.e-05 5.e-05]\n",
      "[1.2e-05 3.6e-05]\n",
      "[8.0e-06 2.8e-05]\n",
      "[6.e-06 2.e-05]\n",
      "[4.0e-06 1.4e-05]\n",
      "[2.e-06 1.e-05]\n",
      "[2.e-06 8.e-06]\n",
      "[2.e-06 6.e-06]\n",
      "[2.e-06 4.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "Episode [1500/1500]\tAverage Shortfall for Agent1: $342,143.56\n",
      "Episode [1500/1500]\tAverage Shortfall for Agent2: $348,499.48\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_le-6_competition_trajectory_1500.npy.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $1,177,354.62\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $1,183,580.64\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $1,257,995.97\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $1,272,524.00\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $695,096.68\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $801,598.95\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $329,916.66\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $337,108.06\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $632,122.09 \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $641,731.72 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_le-6_corporatition_shortfall_list.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.761694 0.656324]\n",
      "[0.603648 0.454928]\n",
      "[0.44365  0.334226]\n",
      "[0.305346 0.25539 ]\n",
      "[0.20247  0.202642]\n",
      "[0.13316  0.148788]\n",
      "[0.09197 0.10399]\n",
      "[0.064072 0.074902]\n",
      "[0.044238 0.052522]\n",
      "[0.03257  0.036602]\n",
      "[0.02397  0.024466]\n",
      "[0.018556 0.01732 ]\n",
      "[0.013314 0.011942]\n",
      "[0.009696 0.008204]\n",
      "[0.006774 0.005622]\n",
      "[0.004728 0.003898]\n",
      "[0.003236 0.002704]\n",
      "[0.00228  0.001762]\n",
      "[0.00165 0.00114]\n",
      "[0.001234 0.000778]\n",
      "[0.000932 0.000566]\n",
      "[0.000674 0.000392]\n",
      "[0.000506 0.00029 ]\n",
      "[0.000376 0.000212]\n",
      "[0.000294 0.00015 ]\n",
      "[0.000224 0.000108]\n",
      "[1.66e-04 7.40e-05]\n",
      "[1.14e-04 5.40e-05]\n",
      "[8.2e-05 4.2e-05]\n",
      "[5.8e-05 3.4e-05]\n",
      "[4.0e-05 2.8e-05]\n",
      "[2.6e-05 2.2e-05]\n",
      "[1.8e-05 1.8e-05]\n",
      "[1.2e-05 1.4e-05]\n",
      "[8.e-06 1.e-05]\n",
      "[6.e-06 8.e-06]\n",
      "[4.e-06 6.e-06]\n",
      "[2.e-06 4.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "[2.e-06 2.e-06]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_trajectory_fixed-corporation.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/venukorada/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [400/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [500/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [600/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [700/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [800/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [900/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1000/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1100/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1200/1300]\tAverage Shortfall for Agent2: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n",
      "\n",
      "Average Implementation Shortfall for Agent1: $nan \n",
      "\n",
      "\n",
      "Average Implementation Shortfall for Agent2: $nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
    "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr1 = 1e-6\n",
    "tr2 = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 1300\n",
    "shortfall_list = []\n",
    "shortfall_hist1 = np.array([])\n",
    "shortfall_hist2 = np.array([])\n",
    "shortfall_deque1 = deque(maxlen=100)\n",
    "shortfall_deque2 = deque(maxlen=100)\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        cur_state1 = np.delete(cur_state,8)\n",
    "        cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "        action1 = agent1.act(cur_state1, add_noise = True)\n",
    "        action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        new_state1 = np.delete(new_state,8)\n",
    "        new_state2 = np.delete(new_state,7)\n",
    "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done1 and info.done2:\n",
    "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "            shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "            shortfall_deque2.append(info.implementation_shortfall2)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
    "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
    "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
    "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortfall = np.array(shortfall_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_shortfall_list.npy',shortfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06\n",
      "[1. 1.]\n",
      "[0.778152 1.      ]\n",
      "[0.627577 1.      ]\n",
      "[0.4687 1.    ]\n",
      "[0.327324 1.      ]\n",
      "[0.219856 1.      ]\n",
      "[0.146201 1.      ]\n",
      "[0.101884 1.      ]\n",
      "[0.071515 1.      ]\n",
      "[0.049697 1.      ]\n",
      "[0.036779 1.      ]\n",
      "[0.027186 1.      ]\n",
      "[0.021121 1.      ]\n",
      "[0.015205 1.      ]\n",
      "[0.011104 1.      ]\n",
      "[0.007776 1.      ]\n",
      "[0.00544 1.     ]\n",
      "[0.003729 1.      ]\n",
      "[0.002632 1.      ]\n",
      "[0.001907 1.      ]\n",
      "[0.001427 1.      ]\n",
      "[0.001078 1.      ]\n",
      "[7.81e-04 1.00e+00]\n",
      "[5.87e-04 1.00e+00]\n",
      "[4.36e-04 1.00e+00]\n",
      "[3.4e-04 1.0e+00]\n",
      "[2.6e-04 1.0e+00]\n",
      "[1.92e-04 1.00e+00]\n",
      "[1.33e-04 1.00e+00]\n",
      "[9.7e-05 1.0e+00]\n",
      "[6.8e-05 1.0e+00]\n",
      "[4.6e-05 1.0e+00]\n",
      "[3.e-05 1.e+00]\n",
      "[2.e-05 1.e+00]\n",
      "[1.3e-05 1.0e+00]\n",
      "[9.e-06 1.e+00]\n",
      "[6.e-06 1.e+00]\n",
      "[4.e-06 1.e+00]\n",
      "[3.e-06 1.e+00]\n",
      "[2.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[1.e-06 1.e+00]\n",
      "[0. 1.]\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent1: $nan\n",
      "Episode [1300/1300]\tAverage Shortfall for Agent2: $nan\n"
     ]
    }
   ],
   "source": [
    "print(tr1,tr2)\n",
    "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "env.start_transactions()\n",
    "\n",
    "trajectory = np.zeros([n_trades+1,2])\n",
    "for i in range(n_trades + 1):\n",
    "    trajectory[i] = cur_state[7:]\n",
    "    \n",
    "    print(cur_state[7:])\n",
    "        # Predict the best action for the current state. \n",
    "    cur_state1 = np.delete(cur_state,8)\n",
    "    cur_state2 = np.delete(cur_state,7)\n",
    "        #print(cur_state[5:])\n",
    "    action1 = agent1.act(cur_state1, add_noise = True)\n",
    "    action2 = agent2.act(cur_state2, add_noise = True)\n",
    "        #print(action1,action2)\n",
    "        # Action is performed and new state, reward, info are received. \n",
    "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "    new_state1 = np.delete(new_state,8)\n",
    "    new_state2 = np.delete(new_state,7)\n",
    "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
    "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
    "        # roll over new state\n",
    "    cur_state = new_state\n",
    "\n",
    "    if info.done1 and info.done2:\n",
    "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
    "        shortfall_deque1.append(info.implementation_shortfall1)\n",
    "            \n",
    "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
    "        shortfall_deque2.append(info.implementation_shortfall2)\n",
    "        break\n",
    "        \n",
    "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
    "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('1e-6_optimal.npy.npy',trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import ddpg_agent\n",
    "import model \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rc('xtick',labelsize=14)\n",
    "plt.rc('ytick',labelsize=14)\n",
    "plt.rc('legend',fontsize = 14)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
