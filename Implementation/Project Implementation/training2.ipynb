{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "training2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUGpioJIO1kD",
        "outputId": "5682695d-bca1-4ed6-9ab3-227508061dbf"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS0JTLDgO1kN",
        "outputId": "0b20ea66-da76-46cd-fea0-63a258e57a3b"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "iBzhndhcO1kP",
        "outputId": "1d6595f6-0c36-42da-98ab-b3ac0db4b58f"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "rQe9pG05O1kQ",
        "outputId": "0b062c3a-02f6-4fa2-a0e3-b8a6e2a2089d"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dLJQ3SSO1kR",
        "outputId": "38dfb809-2e05-4114-8d69-d00ae6d92dbc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.35\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.24\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.18\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.71\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.33 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,681.00 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNAorWVZO1kS"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roCoUKVUO1kS"
      },
      "source": [
        "np.save('1e-6_1e-6_cooporation_shorfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDu-H4DVlCmm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E3q6YXjjcy5"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_1e-6_cooporation_shorfall_list.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceUS1YpOO1kS",
        "outputId": "5f05d0de-d752-428e-d939-651915953841"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HonrFUgQO1kT"
      },
      "source": [
        "#np.save('1e-6_1e-6_competition_trajectory_1500.npy',trajectory)\n",
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_1e-6_competition_trajectory_1500.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gsVuLWkO1kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c31a40-da05-4592-e772-08afde20a716"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "G6AT8A4yO1kU",
        "outputId": "4e17c050-e384-4dd2-ce46-778192ead10a"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "oBEmKIOEO1kU",
        "outputId": "e022c485-84ca-489a-91ab-91a2d519aafc"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OCS2oSkO1kU",
        "outputId": "664a03a1-90e2-4c10-ec6e-397444638316"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $0.01\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $2,562,500.00 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $0.01 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ4nnwgqO1kV"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyKb7NExO1kV"
      },
      "source": [
        "np.save('1e-6_shortfall_list.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOZVIDINdQC-"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_shorfall_list.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFKyYsdDO1kV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7324d21-454f-4aea-ef1c-6114a9152e5e"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.778152 1.      ]\n",
            "[0.627577 1.      ]\n",
            "[0.4687 1.    ]\n",
            "[0.327324 1.      ]\n",
            "[0.219856 1.      ]\n",
            "[0.146201 1.      ]\n",
            "[0.101884 1.      ]\n",
            "[0.071515 1.      ]\n",
            "[0.049697 1.      ]\n",
            "[0.036779 1.      ]\n",
            "[0.027186 1.      ]\n",
            "[0.021121 1.      ]\n",
            "[0.015205 1.      ]\n",
            "[0.011104 1.      ]\n",
            "[0.007776 1.      ]\n",
            "[0.00544 1.     ]\n",
            "[0.003729 1.      ]\n",
            "[0.002632 1.      ]\n",
            "[0.001907 1.      ]\n",
            "[0.001427 1.      ]\n",
            "[0.001078 1.      ]\n",
            "[7.81e-04 1.00e+00]\n",
            "[5.87e-04 1.00e+00]\n",
            "[4.36e-04 1.00e+00]\n",
            "[3.4e-04 1.0e+00]\n",
            "[2.6e-04 1.0e+00]\n",
            "[1.92e-04 1.00e+00]\n",
            "[1.33e-04 1.00e+00]\n",
            "[9.7e-05 1.0e+00]\n",
            "[6.8e-05 1.0e+00]\n",
            "[4.6e-05 1.0e+00]\n",
            "[3.e-05 1.e+00]\n",
            "[2.e-05 1.e+00]\n",
            "[1.3e-05 1.0e+00]\n",
            "[9.e-06 1.e+00]\n",
            "[6.e-06 1.e+00]\n",
            "[4.e-06 1.e+00]\n",
            "[3.e-06 1.e+00]\n",
            "[2.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[0. 1.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHJDnbvsdivb"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_trajectory_1500.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbW_geMoO1kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd7ec48-be91-4c60-9afd-0ab822e66614"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufhY5_zO1kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "11109324-b612-4dbd-d6d0-6f4912bce82c"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqNNXtbVO1kY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "be7c464e-c035-43eb-cc7a-b3431785e898"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>300,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>700,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6uqX9JPO1kZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05f9ae9-e5d7-487f-991f-0a35ab5c3864"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $705,887.29\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,665,016.69\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $768,639.85\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,793,241.57\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $768,750.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $1,793,750.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $749,953.01\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $1,771,843.60\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $283,857.43\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $694,621.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $239,627.79\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $424,206.05\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $425,161.16\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $561,078.48\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $419,305.60\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $508,430.64\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $415,299.91\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $496,613.31\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $603,960.16 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $1,298,753.95 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mkw8wMKO1kZ"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD2EGgptO1ka"
      },
      "source": [
        "np.save('1e-6_shortfall_list 0.3M.npy',shortfall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KuvhxwSstCp"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_shortfall_list 0.3M.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFqt6jY3O1ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb2103b-1b03-4f84-c5b4-eea294034f33"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.         0.65632429]\n",
            "[0.         0.45492857]\n",
            "[0.         0.33422571]\n",
            "[0.      0.25539]\n",
            "[0.         0.20264286]\n",
            "[0.         0.14878714]\n",
            "[0.         0.10398857]\n",
            "[0.     0.0749]\n",
            "[0.         0.05252143]\n",
            "[0.         0.03660143]\n",
            "[0.         0.02446571]\n",
            "[0.      0.01732]\n",
            "[0.         0.01194286]\n",
            "[0.         0.00820429]\n",
            "[0.         0.00562286]\n",
            "[0.         0.00389857]\n",
            "[0.         0.00270286]\n",
            "[0.      0.00176]\n",
            "[0.         0.00113857]\n",
            "[0.         0.00077714]\n",
            "[0.         0.00056571]\n",
            "[0.         0.00039143]\n",
            "[0.         0.00028857]\n",
            "[0.         0.00021143]\n",
            "[0.      0.00015]\n",
            "[0.         0.00010857]\n",
            "[0.00000000e+00 7.57142857e-05]\n",
            "[0.00000000e+00 5.42857143e-05]\n",
            "[0.00000000e+00 4.14285714e-05]\n",
            "[0.00000000e+00 3.28571429e-05]\n",
            "[0.00000000e+00 2.57142857e-05]\n",
            "[0.e+00 2.e-05]\n",
            "[0.00000000e+00 1.57142857e-05]\n",
            "[0.00000000e+00 1.28571429e-05]\n",
            "[0.e+00 1.e-05]\n",
            "[0.00000000e+00 7.14285714e-06]\n",
            "[0.00000000e+00 5.71428571e-06]\n",
            "[0.00000000e+00 4.28571429e-06]\n",
            "[0.00000000e+00 2.85714286e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "[0.00000000e+00 1.42857143e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $414,982.58\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $502,070.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJYZkIrNs9cq"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_trajectory_0.3M.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVKDPYhGO1ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d64eca2-b2e3-4ace-86c1-13fe3bea22f6"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l7MF7XNO1ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "974434a0-47e1-404e-b015-231ced9f7686"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LSTbf0OO1kb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "c0e9a164-10fe-477b-8111-1ea385b93794"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>700,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>300,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSfV1_v_O1kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc70e5b-b2a6-4a4b-ca89-602da0a88d38"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $1,636,719.63\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $708,470.84\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,793,749.54\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $768,749.40\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,793,750.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $768,750.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $1,793,414.77\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $768,695.70\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $1,777,672.76\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $765,635.58\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $1,046,875.05\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $487,660.18\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $506,808.27\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $215,853.32\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $428,751.26\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $180,610.06\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $483,513.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $204,906.77\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $448,318.97\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $190,069.76\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $460,358.29\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $198,355.31\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $423,276.09\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $180,494.91\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $414,774.59\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $175,431.09\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $1,000,614.02 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $431,821.76 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmyV3F6IO1kb"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hc9Bi5CO1kb"
      },
      "source": [
        "np.save('1e-6_shortfall_list 0.7M.npy',shortfall)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jV42KCjvrj8"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_shortfall_list 0.7M.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ZiC4ZkO1kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ed1a61-1f2d-43e9-dcc9-660fa2c88bc0"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.76169286 0.65632333]\n",
            "[0.60364714 0.45493   ]\n",
            "[0.44365    0.33422667]\n",
            "[0.30534571 0.25539   ]\n",
            "[0.20247    0.20264333]\n",
            "[0.13316143 0.14878667]\n",
            "[0.09197 0.10399]\n",
            "[0.06407143 0.0749    ]\n",
            "[0.04423714 0.05252   ]\n",
            "[0.03257 0.0366 ]\n",
            "[0.02396857 0.02446333]\n",
            "[0.01855571 0.01731667]\n",
            "[0.01331429 0.01194   ]\n",
            "[0.00969571 0.00820333]\n",
            "[0.00677286 0.00562333]\n",
            "[0.00472857 0.0039    ]\n",
            "[0.00323571 0.00270333]\n",
            "[0.00228 0.00176]\n",
            "[0.00165 0.00114]\n",
            "[0.00123286 0.00077667]\n",
            "[0.00093    0.00056333]\n",
            "[0.00067286 0.00039   ]\n",
            "[0.00050571 0.00028667]\n",
            "[0.00037571 0.00021   ]\n",
            "[0.00029286 0.00015   ]\n",
            "[0.00022429 0.00010667]\n",
            "[1.65714286e-04 7.33333333e-05]\n",
            "[1.14285714e-04 5.33333333e-05]\n",
            "[8.28571429e-05 4.00000000e-05]\n",
            "[5.85714286e-05 3.00000000e-05]\n",
            "[4.00000000e-05 2.33333333e-05]\n",
            "[2.57142857e-05 1.66666667e-05]\n",
            "[1.71428571e-05 1.33333333e-05]\n",
            "[1.14285714e-05 1.00000000e-05]\n",
            "[8.57142857e-06 6.66666667e-06]\n",
            "[5.71428571e-06 6.66666667e-06]\n",
            "[4.28571429e-06 3.33333333e-06]\n",
            "[2.85714286e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "[1.42857143e-06 3.33333333e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $421,010.24\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $177,686.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoRfX8EDtEPF"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_trajectory_0.7M.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJYN7RmO1kc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1444f55-1019-410d-cdc8-ebb82986b133"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPJX2rwbO1kc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "5ce7702f-5b1b-4669-d723-d7196b72b025"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o24uBXddO1kc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "15b0a8e3-3007-4048-ee12-20ca10a2efa9"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>       <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>0.0001</td>   <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvqINFF4O1kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fbc7dd-fdc0-4702-ac76-355062a46abf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $0.01\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $0.00\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $2,562,500.00 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $0.01 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wQ9HtcCO1kd"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv2sW_PQO1kd"
      },
      "source": [
        "np.save('1e-6_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lujo0NA1yuDn"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_shortfall_optimal.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXMcZFheO1kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f3ed79-6a14-4588-c4a9-f90e31c561ba"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.778152 1.      ]\n",
            "[0.627577 1.      ]\n",
            "[0.4687 1.    ]\n",
            "[0.327324 1.      ]\n",
            "[0.219856 1.      ]\n",
            "[0.146201 1.      ]\n",
            "[0.101884 1.      ]\n",
            "[0.071515 1.      ]\n",
            "[0.049697 1.      ]\n",
            "[0.036779 1.      ]\n",
            "[0.027186 1.      ]\n",
            "[0.021121 1.      ]\n",
            "[0.015205 1.      ]\n",
            "[0.011104 1.      ]\n",
            "[0.007776 1.      ]\n",
            "[0.00544 1.     ]\n",
            "[0.003729 1.      ]\n",
            "[0.002632 1.      ]\n",
            "[0.001907 1.      ]\n",
            "[0.001427 1.      ]\n",
            "[0.001078 1.      ]\n",
            "[7.81e-04 1.00e+00]\n",
            "[5.87e-04 1.00e+00]\n",
            "[4.36e-04 1.00e+00]\n",
            "[3.4e-04 1.0e+00]\n",
            "[2.6e-04 1.0e+00]\n",
            "[1.92e-04 1.00e+00]\n",
            "[1.33e-04 1.00e+00]\n",
            "[9.7e-05 1.0e+00]\n",
            "[6.8e-05 1.0e+00]\n",
            "[4.6e-05 1.0e+00]\n",
            "[3.e-05 1.e+00]\n",
            "[2.e-05 1.e+00]\n",
            "[1.3e-05 1.0e+00]\n",
            "[9.e-06 1.e+00]\n",
            "[6.e-06 1.e+00]\n",
            "[4.e-06 1.e+00]\n",
            "[3.e-06 1.e+00]\n",
            "[2.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[1.e-06 1.e+00]\n",
            "[0. 1.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3nO0GJGzuIm"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_trajectory_optimal.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3p5z4fO1ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6270499e-a22d-45f3-9f2e-d46981e6e23b"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-HsX2guO1ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "587caf97-c8e7-43be-a778-a54422f78c8a"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF1C_bH3O1ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "22b8c350-52c9-4df1-a07c-0c50ed08d600"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>0.0001</td>   <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>       <td>1,000,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>    <td>0</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5TcM61PO1ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad2ecfd9-9b5f-48f6-cf25-d9742ce0a6e4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $nan\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $nan\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $0.01\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $0.01 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $2,562,500.00 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1FxxK5sO1kf"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5S5upFO1kf"
      },
      "source": [
        "np.save('1e-9_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "086LeW1I4VWs"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-9_shortfall_optimal.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZtseR5HO1kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468a2b01-067a-4e33-ae09-a77d74f05230"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[1.       0.635651]\n",
            "[1.      0.42943]\n",
            "[1.       0.309079]\n",
            "[1.       0.232251]\n",
            "[1.       0.181777]\n",
            "[1.     0.1318]\n",
            "[1.       0.091089]\n",
            "[1.       0.065006]\n",
            "[1.       0.045217]\n",
            "[1.       0.031294]\n",
            "[1.       0.020791]\n",
            "[1.       0.014646]\n",
            "[1.       0.010056]\n",
            "[1.       0.006883]\n",
            "[1.       0.004702]\n",
            "[1.       0.003252]\n",
            "[1.      0.00225]\n",
            "[1.       0.001463]\n",
            "[1.00e+00 9.45e-04]\n",
            "[1.00e+00 6.44e-04]\n",
            "[1.00e+00 4.68e-04]\n",
            "[1.00e+00 3.24e-04]\n",
            "[1.00e+00 2.39e-04]\n",
            "[1.00e+00 1.75e-04]\n",
            "[1.00e+00 1.24e-04]\n",
            "[1.0e+00 8.9e-05]\n",
            "[1.0e+00 6.2e-05]\n",
            "[1.0e+00 4.5e-05]\n",
            "[1.0e+00 3.4e-05]\n",
            "[1.0e+00 2.7e-05]\n",
            "[1.0e+00 2.1e-05]\n",
            "[1.0e+00 1.6e-05]\n",
            "[1.0e+00 1.3e-05]\n",
            "[1.0e+00 1.1e-05]\n",
            "[1.e+00 8.e-06]\n",
            "[1.e+00 6.e-06]\n",
            "[1.e+00 4.e-06]\n",
            "[1.e+00 3.e-06]\n",
            "[1.e+00 2.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1.e+00 1.e-06]\n",
            "[1. 0.]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $0.00\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $2,562,500.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew3ma0i54k32"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-9_trajectory_optimal.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvggJwLpO1kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb02413c-d534-45ab-a527-50bef58e413a"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iovlIJ6O1kg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "28cdc99d-e16d-4ec2-c729-8a510ee91bb9"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT94uz6kO1kg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "b0e8f69d-3f9d-4591-846e-4ca2e4995bc7"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th> <td>0.0001</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-09</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDlA0fsXO1kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5e3fc9-39ea-417e-cefe-bf803ab073c8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.77\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.19\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.16\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.70\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.36 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,680.99 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gldpNOlEO1kh"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIyo7Y3O1kh"
      },
      "source": [
        "np.save('1e-4_le-9_shortfall_optimal.npy',shortfall)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-bEei54-FYJ"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-4_1e-9_shortfall_optimal.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_lEn-2O1kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc3253d-def4-4b52-b410-4ad6663fd755"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MYjgNdf-Pf8"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-4_1e-9_trajectory_optimal.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voegn0WyO1ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff13e582-dd3f-4696-f6e4-66293a503bc5"
      },
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7CAgAWuO1ki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "4f05cb87-7673-4eb5-a1d1-89f84a240bc0"
      },
      "source": [
        "financial_params"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXfhYOGzO1ki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "9dabedb9-d282-4941-f7c1-330e2d8830a5"
      },
      "source": [
        "ac_params"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent1 to Sell:</th>        <td>500,000</td> <th>  Fixed Cost of Selling per Share:</th>    <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Total Number of Shares for Agent2 to Sell:</th>        <td>500,000</td> <th>  Trader's Risk Aversion for Agent 1:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>  <th>  Trader's Risk Aversion for Agent 2:</th>  <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td> <th>  Permanent Impact Constant:</th>          <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>    <th>  Single Step Variance:</th>                <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>    <th>  Time Interval between trades:</th>         <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ln59YDAO1kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6c3e2c-52d4-4069-e03f-de405f70a8eb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import syntheticChrissAlmgren as sca\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "# Create simulation environment\n",
        "env = sca.MarketEnvironment()\n",
        "\n",
        "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
        "agent1 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 1225)\n",
        "agent2 = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(),random_seed = 108)\n",
        "# Set the liquidation time\n",
        "lqt = 60\n",
        "\n",
        "# Set the number of trades\n",
        "n_trades = 60\n",
        "\n",
        "# Set trader's risk aversion\n",
        "tr1 = 1e-6\n",
        "tr2 = 1e-6\n",
        "\n",
        "# Set the number of episodes to run the simulation\n",
        "episodes = 1300\n",
        "shortfall_list = []\n",
        "shortfall_hist1 = np.array([])\n",
        "shortfall_hist2 = np.array([])\n",
        "shortfall_deque1 = deque(maxlen=100)\n",
        "shortfall_deque2 = deque(maxlen=100)\n",
        "for episode in range(episodes): \n",
        "    # Reset the enviroment\n",
        "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "    env.start_transactions()\n",
        "\n",
        "    for i in range(n_trades + 1):\n",
        "      \n",
        "        # Predict the best action for the current state. \n",
        "        cur_state1 = np.delete(cur_state,8)\n",
        "        cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "        action1 = agent1.act(cur_state1, add_noise = True)\n",
        "        action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "        new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "        new_state1 = np.delete(new_state,8)\n",
        "        new_state2 = np.delete(new_state,7)\n",
        "        agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "        agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "        cur_state = new_state\n",
        "\n",
        "        if info.done1 and info.done2:\n",
        "            shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "            shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "            shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "            shortfall_deque2.append(info.implementation_shortfall2)\n",
        "            break\n",
        "        \n",
        "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "        print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))\n",
        "        shortfall_list.append([np.mean(shortfall_deque1),np.mean(shortfall_deque2)])\n",
        "print('\\nAverage Implementation Shortfall for Agent1: ${:,.2f} \\n'.format(np.mean(shortfall_hist1)))\n",
        "print('\\nAverage Implementation Shortfall for Agent2: ${:,.2f} \\n'.format(np.mean(shortfall_hist2)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpisode [100/1300]\tAverage Shortfall for Agent1: $1,168,737.12\n",
            "Episode [100/1300]\tAverage Shortfall for Agent2: $1,182,497.04\n",
            "Episode [200/1300]\tAverage Shortfall for Agent1: $1,281,250.00\n",
            "Episode [200/1300]\tAverage Shortfall for Agent2: $1,281,250.00\n",
            "Episode [300/1300]\tAverage Shortfall for Agent1: $1,274,753.86\n",
            "Episode [300/1300]\tAverage Shortfall for Agent2: $1,278,818.43\n",
            "Episode [400/1300]\tAverage Shortfall for Agent1: $958,446.77\n",
            "Episode [400/1300]\tAverage Shortfall for Agent2: $996,403.19\n",
            "Episode [500/1300]\tAverage Shortfall for Agent1: $321,537.16\n",
            "Episode [500/1300]\tAverage Shortfall for Agent2: $321,944.70\n",
            "Episode [600/1300]\tAverage Shortfall for Agent1: $331,625.64\n",
            "Episode [600/1300]\tAverage Shortfall for Agent2: $328,738.83\n",
            "Episode [700/1300]\tAverage Shortfall for Agent1: $302,789.39\n",
            "Episode [700/1300]\tAverage Shortfall for Agent2: $296,596.55\n",
            "Episode [800/1300]\tAverage Shortfall for Agent1: $305,151.05\n",
            "Episode [800/1300]\tAverage Shortfall for Agent2: $301,542.19\n",
            "Episode [900/1300]\tAverage Shortfall for Agent1: $343,508.22\n",
            "Episode [900/1300]\tAverage Shortfall for Agent2: $342,052.92\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent1: $318,731.56\n",
            "Episode [1000/1300]\tAverage Shortfall for Agent2: $317,495.71\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent1: $329,135.85\n",
            "Episode [1100/1300]\tAverage Shortfall for Agent2: $333,255.71\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent1: $300,993.44\n",
            "Episode [1200/1300]\tAverage Shortfall for Agent2: $301,320.57\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $294,413.69\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $292,937.04\n",
            "\n",
            "Average Implementation Shortfall for Agent1: $579,313.36 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for Agent2: $582,680.99 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfloNsJbO1kj"
      },
      "source": [
        "shortfall = np.array(shortfall_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhU8L7EEO1kj"
      },
      "source": [
        "np.save('1e-6_le-6_competition_shortfall_list.npy',shortfall)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-e26OK9ASst"
      },
      "source": [
        "import pandas as pd\n",
        "df_shortfall = pd.DataFrame(shortfall) \n",
        "# saving the dataframe \n",
        "df_shortfall.to_csv('1e-6_le-6_competition_shortfall_list.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTTTUHy0O1kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56131d63-c72e-421e-9a86-1478cc033210"
      },
      "source": [
        "print(tr1,tr2)\n",
        "cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb1 = tr1,lamb2 = tr2)\n",
        "\n",
        "    # set the environment to make transactions\n",
        "env.start_transactions()\n",
        "\n",
        "trajectory = np.zeros([n_trades+1,2])\n",
        "for i in range(n_trades + 1):\n",
        "    trajectory[i] = cur_state[7:]\n",
        "    \n",
        "    print(cur_state[7:])\n",
        "        # Predict the best action for the current state. \n",
        "    cur_state1 = np.delete(cur_state,8)\n",
        "    cur_state2 = np.delete(cur_state,7)\n",
        "        #print(cur_state[5:])\n",
        "    action1 = agent1.act(cur_state1, add_noise = True)\n",
        "    action2 = agent2.act(cur_state2, add_noise = True)\n",
        "        #print(action1,action2)\n",
        "        # Action is performed and new state, reward, info are received. \n",
        "    new_state, reward1, reward2, done1, done2, info = env.step(action1,action2)\n",
        "        \n",
        "        # current state, action, reward, new state are stored in the experience replay\n",
        "    new_state1 = np.delete(new_state,8)\n",
        "    new_state2 = np.delete(new_state,7)\n",
        "    agent1.step(cur_state1, action1, reward1, new_state1, done1)\n",
        "    agent2.step(cur_state2, action2, reward2, new_state2, done2)\n",
        "        # roll over new state\n",
        "    cur_state = new_state\n",
        "\n",
        "    if info.done1 and info.done2:\n",
        "        shortfall_hist1 = np.append(shortfall_hist1, info.implementation_shortfall1)\n",
        "        shortfall_deque1.append(info.implementation_shortfall1)\n",
        "            \n",
        "        shortfall_hist2 = np.append(shortfall_hist2, info.implementation_shortfall2)\n",
        "        shortfall_deque2.append(info.implementation_shortfall2)\n",
        "        break\n",
        "        \n",
        "if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent1: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque1)))        \n",
        "    print('\\rEpisode [{}/{}]\\tAverage Shortfall for Agent2: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque2)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1e-06 1e-06\n",
            "[1. 1.]\n",
            "[0.761694 0.656324]\n",
            "[0.603648 0.454928]\n",
            "[0.44365  0.334226]\n",
            "[0.305346 0.25539 ]\n",
            "[0.20247  0.202642]\n",
            "[0.13316  0.148788]\n",
            "[0.09197 0.10399]\n",
            "[0.064072 0.074902]\n",
            "[0.044238 0.052522]\n",
            "[0.03257  0.036602]\n",
            "[0.02397  0.024466]\n",
            "[0.018556 0.01732 ]\n",
            "[0.013314 0.011942]\n",
            "[0.009696 0.008204]\n",
            "[0.006774 0.005622]\n",
            "[0.004728 0.003898]\n",
            "[0.003236 0.002704]\n",
            "[0.00228  0.001762]\n",
            "[0.00165 0.00114]\n",
            "[0.001234 0.000778]\n",
            "[0.000932 0.000566]\n",
            "[0.000674 0.000392]\n",
            "[0.000506 0.00029 ]\n",
            "[0.000376 0.000212]\n",
            "[0.000294 0.00015 ]\n",
            "[0.000224 0.000108]\n",
            "[1.66e-04 7.40e-05]\n",
            "[1.14e-04 5.40e-05]\n",
            "[8.2e-05 4.2e-05]\n",
            "[5.8e-05 3.4e-05]\n",
            "[4.0e-05 2.8e-05]\n",
            "[2.6e-05 2.2e-05]\n",
            "[1.8e-05 1.8e-05]\n",
            "[1.2e-05 1.4e-05]\n",
            "[8.e-06 1.e-05]\n",
            "[6.e-06 8.e-06]\n",
            "[4.e-06 6.e-06]\n",
            "[2.e-06 4.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "[2.e-06 2.e-06]\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent1: $298,868.72\n",
            "Episode [1300/1300]\tAverage Shortfall for Agent2: $296,739.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OLdiLzCO1kk"
      },
      "source": [
        "trajectory_array = np.array(trajectory)\n",
        "df_trajectory = pd.DataFrame(trajectory_array)\n",
        "df_trajectory.to_csv('1e-6_trajectory_fixed-competitor.csv')\n",
        "np.save('1e-6_trajectory_fixed-competitor.npy',trajectory)"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}