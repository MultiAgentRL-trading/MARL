{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppleStock_usingFINRL_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U4XebRCpdUo",
        "outputId": "c056581c-1431-497a-e744-c66cd2bac6e7"
      },
      "source": [
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-gqkxlvif\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-gqkxlvif\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (1.1.5)\n",
            "Collecting stockstats\n",
            "  Downloading https://files.pythonhosted.org/packages/32/41/d3828c5bc0a262cb3112a4024108a3b019c183fa3b3078bff34bf25abf91/stockstats-0.3.2-py2.py3-none-any.whl\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/97/f6da6fcaa96934832c02acf95a32309cfa8646b010221f6c7a14bfcf40d0/stable_baselines3-0.11.1-py3-none-any.whl (152kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (54.0.0)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.36.2)\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-450id65g/pyfolio\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-450id65g/pyfolio\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.3.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.3.0) (2.8.1)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/43/27/31803df15173ab341fe7548c14154b54227dfd8f630daa09a1c6e7db52f7/int_date-0.1.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.0) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/88/b25778f17e5320c1c58f8c5060fb5b037288e162bd7554c30799e9ea90db/lxml-4.6.2-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (0.10.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (1.7.1+cu101)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (4.1.2.30)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (0.2.6)\n",
            "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (2.4.1)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (7.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (8.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.10.0)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (5.5.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.11.1)\n",
            "Collecting empyrical>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->stable-baselines3[extra]->finrl==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.27.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.10.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.7.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.2.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.4.0)\n",
            "Building wheels for collected packages: finrl, yfinance, pyfolio, empyrical\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.0-cp37-none-any.whl size=38201 sha256=6e8c6c2c0b4399e45cf0075f69e921e793eb8abe4d032e5293b263b93fae8aef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-svh4w1i1/wheels/9c/19/bf/c644def96612df1ad42c94d5304966797eaa3221dffc5efe0b\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=5f62e697d666dd3c576c199aa08204bb1b57d5a576f87d5919fc85d6d01e76cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-cp37-none-any.whl size=75764 sha256=ad750ed37be56f1a068012e4b608f4e74776189462327b805f5285311baf2323\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-svh4w1i1/wheels/43/ce/d9/6752fb6e03205408773235435205a0519d2c608a94f1976e56\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-cp37-none-any.whl size=39764 sha256=0b8938fd4a6d4478cb8c73c4d27eef4018b4b85d81a53ac645b00830b6e22bb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
            "Successfully built finrl yfinance pyfolio empyrical\n",
            "Installing collected packages: int-date, stockstats, lxml, yfinance, stable-baselines3, empyrical, pyfolio, finrl\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed empyrical-0.5.5 finrl-0.3.0 int-date-0.1.8 lxml-4.6.2 pyfolio-0.9.2+75.g4b901f6 stable-baselines3-0.11.1 stockstats-0.3.2 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sV6EPYwpjDe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_stocktrading import StockTradingEnv\n",
        "from finrl.model.models import DRLAgent\n",
        "#from finrl.trade.backtest import backtest_stats, baseline_stats, backtest_plot\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfg_jKazpugT"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPuiNP4yp5BY"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8MZ8GDTap_Zs",
        "outputId": "3a1f28c3-e397-4e0e-c66d-136cadd442e4"
      },
      "source": [
        "# from config.py start_date is a string\n",
        "config.START_DATE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2000-01-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tpnkSjL4qAsJ",
        "outputId": "9d6e8364-8bdb-4432-9d76-f04283e7f4c9"
      },
      "source": [
        "# from config.py end_date is a string\n",
        "config.END_DATE"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-01-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCG-seqqHA-",
        "outputId": "8f842fa9-dea3-474d-db1b-7c7f53bd06d9"
      },
      "source": [
        "# Download and save the data in a pandas DataFrame:\n",
        "data_df = YahooDownloader(start_date = '2009-01-01',\n",
        "                          end_date = '2021-01-01',\n",
        "                          ticker_list = ['AAPL']).fetch_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3021, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUrtPNjYqLFv",
        "outputId": "3c31ecaf-968f-42f8-ffd6-c3a6eb04fa29"
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3021, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9CxM9RIlqMdW",
        "outputId": "dbc89567-10e0-438d-ef17-d865002039ce"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.909563</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.861573</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223571</td>\n",
              "      <td>2.799739</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.851728</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high       low     close      volume   tic  day\n",
              "0  2009-01-02  3.067143  3.251429  3.041429  2.791740   746015200  AAPL    4\n",
              "1  2009-01-05  3.327500  3.435000  3.311071  2.909563  1181608400  AAPL    0\n",
              "2  2009-01-06  3.426786  3.470357  3.299643  2.861573  1289310400  AAPL    1\n",
              "3  2009-01-07  3.278929  3.303571  3.223571  2.799739   753048800  AAPL    2\n",
              "4  2009-01-08  3.229643  3.326786  3.215714  2.851728   673500800  AAPL    3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ehKHtyeqVRl",
        "outputId": "3be6cff8-73be-483e-94da-4278dbc67722"
      },
      "source": [
        "## we store the stockstats technical indicator column names in config.py\n",
        "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bonWJGypqYw3",
        "outputId": "2b57cd50-0151-4726-8c06-aadc6cfe521c"
      },
      "source": [
        "## user can add more technical indicators\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IU1z142qcF7",
        "outputId": "fd9cdbed-925b-4900-f752-dc96d213b8b6"
      },
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = tech_indicator_list,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "data_df = fe.preprocess_data(data_df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "TckZGWrYqfUQ",
        "outputId": "619237a7-3892-4551-fefc-246d08a35fe7"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.017278</td>\n",
              "      <td>2.684025</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>-6.299850</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>1.0</td>\n",
              "      <td>218.899551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.909563</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>3.017278</td>\n",
              "      <td>2.684025</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>-15.368278</td>\n",
              "      <td>3.197322</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>2.0</td>\n",
              "      <td>133.505133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.861573</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001880</td>\n",
              "      <td>2.972787</td>\n",
              "      <td>2.735796</td>\n",
              "      <td>70.355711</td>\n",
              "      <td>46.771878</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>-24.222698</td>\n",
              "      <td>3.377143</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>3.0</td>\n",
              "      <td>141.931537</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223571</td>\n",
              "      <td>2.799739</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.000746</td>\n",
              "      <td>2.951725</td>\n",
              "      <td>2.729582</td>\n",
              "      <td>50.429389</td>\n",
              "      <td>-29.777993</td>\n",
              "      <td>43.607834</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>-34.930948</td>\n",
              "      <td>3.352857</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>156.347447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.195393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.851728</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000088</td>\n",
              "      <td>2.939568</td>\n",
              "      <td>2.746169</td>\n",
              "      <td>60.227126</td>\n",
              "      <td>-9.019317</td>\n",
              "      <td>48.357918</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>-38.029528</td>\n",
              "      <td>3.254286</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>5.0</td>\n",
              "      <td>144.226688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high  ...       wr_10  dma      trix\n",
              "0  2009-01-02  3.067143  3.251429  ...  218.899551  0.0  0.670734\n",
              "1  2009-01-05  3.327500  3.435000  ...  133.505133  0.0  0.670734\n",
              "2  2009-01-06  3.426786  3.470357  ...  141.931537  0.0  0.391304\n",
              "3  2009-01-07  3.278929  3.303571  ...  156.347447  0.0  0.195393\n",
              "4  2009-01-08  3.229643  3.326786  ...  144.226688  0.0  0.125125\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsYcJ5Ewqkau"
      },
      "source": [
        "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
        "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
        "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pDuAROrqmWY",
        "outputId": "45dc8e5b-7baf-43da-9c33-f86473d1ba97"
      },
      "source": [
        "\n",
        "## we store the stockstats technical indicator column names in config.py\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma',\n",
              " 'kdjk',\n",
              " 'open_2_sma',\n",
              " 'boll',\n",
              " 'close_10.0_le_5_c',\n",
              " 'wr_10',\n",
              " 'dma',\n",
              " 'trix']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55XH4mfLqvPG",
        "outputId": "b4eb4011-3af7-4972-bc35-686005aa58af"
      },
      "source": [
        "\n",
        "# the stock dimension is 1, because we only use the price data of AAPL.\n",
        "len(train.tic.unique())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMnVqQKqywu",
        "outputId": "216c4c21-163a-4b28-f215-e98c89d048d7"
      },
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stock Dimension: 1, State Space: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxWZIhhsq0Ga"
      },
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 100000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4\n",
        "    \n",
        "}\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udKmycKZq6KS",
        "outputId": "4afa40d0-02e1-4da3-be44-ef266936b96f"
      },
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-PYHx7eq-Ox"
      },
      "source": [
        "\n",
        "agent = DRLAgent(env = env_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztFgaddl0W3T"
      },
      "source": [
        "## A2C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c22Ml99xrB49",
        "outputId": "052f1f06-bdc6-40fb-e577-595cc46394a4"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbz3mCV4rD54",
        "outputId": "bfd5a8fb-104d-4d5b-dd6e-cd3b7bed5201"
      },
      "source": [
        "\n",
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=50000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/a2c/a2c_1\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.44    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -0.00567 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000111 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 210       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.44     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -0.482    |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.177     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 239      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0.429    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.638   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.309    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 260      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -1.27    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.478   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.132    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 271      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.44    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.22     |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.594    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.2e+05  |\n",
            "|    total_cost         | 3.39e+03 |\n",
            "|    total_reward       | 2.2e+05  |\n",
            "|    total_reward_pct   | 220      |\n",
            "|    total_trades       | 2489     |\n",
            "| time/                 |          |\n",
            "|    fps                | 281      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0225   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.000614 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 288      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.193    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.0165   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 294       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.45     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 0.389     |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.0677    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 299      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.281   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0441   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 302      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -0.137   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -2.08    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.54     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2e+05    |\n",
            "|    total_cost         | 3.32e+03 |\n",
            "|    total_reward       | 9.96e+04 |\n",
            "|    total_reward_pct   | 99.6     |\n",
            "|    total_trades       | 2495     |\n",
            "| time/                 |          |\n",
            "|    fps                | 304      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.11     |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.00499  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | -0.0839  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.521   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.172    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.542    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.26     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 310      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.0756  |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.00343  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 312      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.561   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.752    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.61e+05 |\n",
            "|    total_cost         | 3.37e+03 |\n",
            "|    total_reward       | 1.61e+05 |\n",
            "|    total_reward_pct   | 161      |\n",
            "|    total_trades       | 2493     |\n",
            "| time/                 |          |\n",
            "|    fps                | 315      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.125    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0148   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0.365    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.252   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.079    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0.000988 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.072   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0798   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 317      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | 0.0719   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.201   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0584   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -0.346   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -1.13    |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.809    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.27e+05 |\n",
            "|    total_cost         | 3.3e+03  |\n",
            "|    total_reward       | 3.27e+05 |\n",
            "|    total_reward_pct   | 327      |\n",
            "|    total_trades       | 2499     |\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.247    |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.068    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -0.347   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0679   |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.104    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 319      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.0815   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.737    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.361    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 320      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.58    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.309    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.104    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 320      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.208    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 3.21     |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 3.29     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.44e+05 |\n",
            "|    total_cost         | 3.35e+03 |\n",
            "|    total_reward       | 3.44e+05 |\n",
            "|    total_reward_pct   | 344      |\n",
            "|    total_trades       | 2496     |\n",
            "| time/                 |          |\n",
            "|    fps                | 320      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | -0.104   |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.00859  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.588   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 1.6      |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.807    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.745   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.809    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.283    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.464    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -0.0371  |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0235   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.0554  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 2.23     |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 2.52     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.59e+05 |\n",
            "|    total_cost         | 3.14e+03 |\n",
            "|    total_reward       | 2.59e+05 |\n",
            "|    total_reward_pct   | 259      |\n",
            "|    total_trades       | 2500     |\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -9.99    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.293    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0603   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 49       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.306   |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.428    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.0705  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 1.02     |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.517    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 52       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.295    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.134    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.66    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.486    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.267    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.71e+05 |\n",
            "|    total_cost         | 3.46e+03 |\n",
            "|    total_reward       | 3.71e+05 |\n",
            "|    total_reward_pct   | 371      |\n",
            "|    total_trades       | 2488     |\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.122   |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.00797  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -0.312   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.764    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.367    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 58       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.108    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 0.45     |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0893   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.296    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -0.973   |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.595    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 61       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.327   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.847   |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.548    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.5e+05  |\n",
            "|    total_cost         | 3.41e+03 |\n",
            "|    total_reward       | 2.5e+05  |\n",
            "|    total_reward_pct   | 250      |\n",
            "|    total_trades       | 2489     |\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 63       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | 0.336    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0561   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 65       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -0.581   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | 0.108    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0638   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 66       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | 0.696    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.269    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -0.0499  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | -0.537   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.338    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -0.0927  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | -0.313   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0668   |\n",
            "------------------------------------\n",
            "day: 2515, episode: 10\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 455356.82\n",
            "total_reward: 355356.82\n",
            "total_cost: 3068.20\n",
            "total_trades: 2498\n",
            "Sharpe: 0.798\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.55e+05 |\n",
            "|    total_cost         | 3.07e+03 |\n",
            "|    total_reward       | 3.55e+05 |\n",
            "|    total_reward_pct   | 355      |\n",
            "|    total_trades       | 2498     |\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 71       |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -0.161   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | -0.131   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0516   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 73       |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | -1.59    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 1.92     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | 0.196    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | 0.533    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.122    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 76       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | -0.525   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.143    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 77       |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0.0144   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | 6.74     |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 27.4     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.79e+05 |\n",
            "|    total_cost         | 2.34e+03 |\n",
            "|    total_reward       | 5.79e+05 |\n",
            "|    total_reward_pct   | 579      |\n",
            "|    total_trades       | 2495     |\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | -0.372   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.122    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0.03     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 1.87     |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 2.55     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 82       |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 3.9      |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 4.88     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -0.0319  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | -2.14    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.82     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.0315  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | 1.46     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.07     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.71e+05 |\n",
            "|    total_cost         | 2.14e+03 |\n",
            "|    total_reward       | 5.71e+05 |\n",
            "|    total_reward_pct   | 571      |\n",
            "|    total_trades       | 2497     |\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5600     |\n",
            "|    time_elapsed       | 86       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -1.49    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5599     |\n",
            "|    policy_loss        | 0.0489   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.00211  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | 0.888    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.886    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | 0.028    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.0535   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0.392    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | -0.575   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.214    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 6000     |\n",
            "|    time_elapsed       | 93       |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0.00684  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5999     |\n",
            "|    policy_loss        | -3.4     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 7.19     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.99e+05 |\n",
            "|    total_cost         | 2.65e+03 |\n",
            "|    total_reward       | 5.99e+05 |\n",
            "|    total_reward_pct   | 599      |\n",
            "|    total_trades       | 2492     |\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.709   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | -0.316   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0434   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 6200     |\n",
            "|    time_elapsed       | 96       |\n",
            "|    total_timesteps    | 31000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.16    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6199     |\n",
            "|    policy_loss        | 1.59     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.9      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.139   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | -0.116   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.0172   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0.0112   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 1.56     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 2.3      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 6500     |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 32500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.0351  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6499     |\n",
            "|    policy_loss        | 3.16     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 5.22     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.38e+05 |\n",
            "|    total_cost         | 2.92e+03 |\n",
            "|    total_reward       | 6.38e+05 |\n",
            "|    total_reward_pct   | 638      |\n",
            "|    total_trades       | 2501     |\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 7.15e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -0.267   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0289   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 103      |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | 0.0978   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.118    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 323      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.0141  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | 1.42     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 1.18     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 6900     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 34500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6899     |\n",
            "|    policy_loss        | -0.121   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.226    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 107      |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | -4.14    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 13.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.25e+05 |\n",
            "|    total_cost         | 2.05e+03 |\n",
            "|    total_reward       | 6.25e+05 |\n",
            "|    total_reward_pct   | 625      |\n",
            "|    total_trades       | 2493     |\n",
            "| time/                 |          |\n",
            "|    fps                | 324      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 109      |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | -0.538   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.297    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 324       |\n",
            "|    iterations         | 7200      |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7199      |\n",
            "|    policy_loss        | 1.3       |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.44      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 113      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -0.0692  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | 0.0181   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.156    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 115      |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0.0481   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | -1.06    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.666    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 319      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 117      |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 0.299    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.196    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.46e+05 |\n",
            "|    total_cost         | 1.89e+03 |\n",
            "|    total_reward       | 6.46e+05 |\n",
            "|    total_reward_pct   | 646      |\n",
            "|    total_trades       | 2497     |\n",
            "| time/                 |          |\n",
            "|    fps                | 317      |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 119      |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | -0.225   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0474   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 121      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | -0.0052  |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0194   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 316       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 123       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 0.0203    |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.388     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 124      |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0.0283   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | -1.45    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 1.6      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 126      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | 1.21     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 1.24     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.71e+05 |\n",
            "|    total_cost         | 938      |\n",
            "|    total_reward       | 6.71e+05 |\n",
            "|    total_reward_pct   | 671      |\n",
            "|    total_trades       | 2500     |\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 127      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -1.34    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | 0.215    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0629   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 316      |\n",
            "|    iterations         | 8200     |\n",
            "|    time_elapsed       | 129      |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8199     |\n",
            "|    policy_loss        | -0.17    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0432   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 316       |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.52     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | 1.9       |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 1.07      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 317      |\n",
            "|    iterations         | 8400     |\n",
            "|    time_elapsed       | 132      |\n",
            "|    total_timesteps    | 42000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8399     |\n",
            "|    policy_loss        | -0.423   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.127    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 317      |\n",
            "|    iterations         | 8500     |\n",
            "|    time_elapsed       | 133      |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -0.0405  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8499     |\n",
            "|    policy_loss        | 3.07     |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 4.05     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.79e+05 |\n",
            "|    total_cost         | 704      |\n",
            "|    total_reward       | 6.79e+05 |\n",
            "|    total_reward_pct   | 679      |\n",
            "|    total_trades       | 2509     |\n",
            "| time/                 |          |\n",
            "|    fps                | 317      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 135      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -5.36    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | -0.37    |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.0876   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 8700     |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 43500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8699     |\n",
            "|    policy_loss        | -1.96    |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 1.49     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 8800     |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8799     |\n",
            "|    policy_loss        | -0.386   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.121    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 318      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | -0.0173  |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.237    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 319      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -0.00428 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | 8.94     |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 22.3     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 8.09e+05 |\n",
            "|    total_cost         | 1.16e+03 |\n",
            "|    total_reward       | 7.09e+05 |\n",
            "|    total_reward_pct   | 709      |\n",
            "|    total_trades       | 2495     |\n",
            "| time/                 |          |\n",
            "|    fps                | 319      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 142      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0.829    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -0.251   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.0538   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 319      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 143      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | -1.7     |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 2.25     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 319       |\n",
            "|    iterations         | 9300      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 46500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.52     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9299      |\n",
            "|    policy_loss        | 1.04      |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.322     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 320      |\n",
            "|    iterations         | 9400     |\n",
            "|    time_elapsed       | 146      |\n",
            "|    total_timesteps    | 47000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | -0.0131  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9399     |\n",
            "|    policy_loss        | -0.718   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.464    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 320      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 148      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | 0.787    |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.372    |\n",
            "------------------------------------\n",
            "day: 2515, episode: 20\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 777248.16\n",
            "total_reward: 677248.16\n",
            "total_cost: 1579.96\n",
            "total_trades: 2499\n",
            "Sharpe: 0.957\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.77e+05 |\n",
            "|    total_cost         | 1.58e+03 |\n",
            "|    total_reward       | 6.77e+05 |\n",
            "|    total_reward_pct   | 677      |\n",
            "|    total_trades       | 2499     |\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 149      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | 0.154    |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.0268   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 321      |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 150      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | -0.943   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.635    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 321       |\n",
            "|    iterations         | 9800      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.53     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9799      |\n",
            "|    policy_loss        | 0.29      |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.364     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 9900     |\n",
            "|    time_elapsed       | 153      |\n",
            "|    total_timesteps    | 49500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9899     |\n",
            "|    policy_loss        | -1.49    |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 1.13     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 322      |\n",
            "|    iterations         | 10000    |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 0.019    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9999     |\n",
            "|    policy_loss        | -0.0435  |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.388    |\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ELLp2220b6X"
      },
      "source": [
        "## DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzrsK3x-rTtT",
        "outputId": "1e2ce0ad-57c8-4256-dd02-a3ef9ed42ce0"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
        "\n",
        "\n",
        "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXclIEHFrdE_",
        "outputId": "9df9d75c-0ec9-4630-f31d-555887ce6e4b"
      },
      "source": [
        "\n",
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ddpg/ddpg_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 74       |\n",
            "|    time_elapsed     | 135      |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | -217     |\n",
            "|    critic_loss      | 663      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 7548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 64       |\n",
            "|    time_elapsed     | 313      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | -126     |\n",
            "|    critic_loss      | 121      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 17612    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 30\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 859765.38\n",
            "total_reward: 759765.38\n",
            "total_cost: 99.90\n",
            "total_trades: 2515\n",
            "Sharpe: 0.990\n",
            "=================================\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 61       |\n",
            "|    time_elapsed     | 494      |\n",
            "|    total timesteps  | 30192    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | -70      |\n",
            "|    critic_loss      | 151      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 27676    |\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiLLVAXd0gaG"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FFZ0jfSris7",
        "outputId": "43f8bb6a-d676-44a5-9c77-214f606afb59"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V168XyoTrltG",
        "outputId": "93fbd701-a5b8-49be-a6a2-ea4246db9f80"
      },
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=80000)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ppo/ppo_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 575  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 1.34e+05     |\n",
            "|    total_cost           | 3.14e+03     |\n",
            "|    total_reward         | 3.36e+04     |\n",
            "|    total_reward_pct     | 33.6         |\n",
            "|    total_trades         | 2406         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 517          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013231952 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -0.0331      |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | -0.000772    |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000252    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 0.0323       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.53e+05     |\n",
            "|    total_cost           | 3.16e+03     |\n",
            "|    total_reward         | 1.53e+05     |\n",
            "|    total_reward_pct     | 153          |\n",
            "|    total_trades         | 2483         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 505          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004552621 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.125        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.0347       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000324    |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.0731       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.67e+05     |\n",
            "|    total_cost           | 2.99e+03     |\n",
            "|    total_reward         | 2.67e+05     |\n",
            "|    total_reward_pct     | 267          |\n",
            "|    total_trades         | 2487         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 491          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065914304 |\n",
            "|    clip_fraction        | 0.0484       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.196        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.122        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00361     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.377        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.38e+05     |\n",
            "|    total_cost           | 2.73e+03     |\n",
            "|    total_reward         | 2.38e+05     |\n",
            "|    total_reward_pct     | 238          |\n",
            "|    total_trades         | 2487         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 486          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025708168 |\n",
            "|    clip_fraction        | 0.00376      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.845        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 1.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 483          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012701153 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0505       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.767        |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -7.19e-05    |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 1.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.9e+05      |\n",
            "|    total_cost           | 2.65e+03     |\n",
            "|    total_reward         | 2.9e+05      |\n",
            "|    total_reward_pct     | 290          |\n",
            "|    total_trades         | 2491         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 481          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046713036 |\n",
            "|    clip_fraction        | 0.00083      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.191        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.375        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 0.708        |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 40\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 522260.20\n",
            "total_reward: 422260.20\n",
            "total_cost: 2406.31\n",
            "total_trades: 2493\n",
            "Sharpe: 0.832\n",
            "=================================\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.22e+05     |\n",
            "|    total_cost           | 2.41e+03     |\n",
            "|    total_reward         | 4.22e+05     |\n",
            "|    total_reward_pct     | 422          |\n",
            "|    total_trades         | 2493         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 480          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010685852 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0852       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.966        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 1.75         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| environment/            |                |\n",
            "|    portfolio_value      | 4.98e+05       |\n",
            "|    total_cost           | 2.24e+03       |\n",
            "|    total_reward         | 3.98e+05       |\n",
            "|    total_reward_pct     | 398            |\n",
            "|    total_trades         | 2491           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 479            |\n",
            "|    iterations           | 9              |\n",
            "|    time_elapsed         | 38             |\n",
            "|    total_timesteps      | 18432          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -0.00056417845 |\n",
            "|    clip_fraction        | 9.77e-05       |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.41          |\n",
            "|    explained_variance   | 0.0829         |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 1.23           |\n",
            "|    n_updates            | 80             |\n",
            "|    policy_gradient_loss | -0.000641      |\n",
            "|    std                  | 0.996          |\n",
            "|    value_loss           | 2.74           |\n",
            "--------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 5.55e+05    |\n",
            "|    total_cost           | 2.44e+03    |\n",
            "|    total_reward         | 4.55e+05    |\n",
            "|    total_reward_pct     | 455         |\n",
            "|    total_trades         | 2504        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 479         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004002897 |\n",
            "|    clip_fraction        | 0.00718     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0835      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.54        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0008     |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.75        |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 478            |\n",
            "|    iterations           | 11             |\n",
            "|    time_elapsed         | 47             |\n",
            "|    total_timesteps      | 22528          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -0.00043217646 |\n",
            "|    clip_fraction        | 0.00239        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.42          |\n",
            "|    explained_variance   | 0.0437         |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 1.89           |\n",
            "|    n_updates            | 100            |\n",
            "|    policy_gradient_loss | -0.00111       |\n",
            "|    std                  | 1.01           |\n",
            "|    value_loss           | 3.57           |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 5.74e+05      |\n",
            "|    total_cost           | 2.32e+03      |\n",
            "|    total_reward         | 4.74e+05      |\n",
            "|    total_reward_pct     | 474           |\n",
            "|    total_trades         | 2489          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 478           |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 51            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -0.0010109587 |\n",
            "|    clip_fraction        | 0.000391      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.43         |\n",
            "|    explained_variance   | 0.00279       |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.939         |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -0.000406     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 2.2           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 5.29e+05    |\n",
            "|    total_cost           | 2.57e+03    |\n",
            "|    total_reward         | 4.29e+05    |\n",
            "|    total_reward_pct     | 429         |\n",
            "|    total_trades         | 2501        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005149696 |\n",
            "|    clip_fraction        | 0.0146      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.0514      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.98        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00119    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.8         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 5.24e+05    |\n",
            "|    total_cost           | 2.71e+03    |\n",
            "|    total_reward         | 4.24e+05    |\n",
            "|    total_reward_pct     | 424         |\n",
            "|    total_trades         | 2494        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002709399 |\n",
            "|    clip_fraction        | 0.0218      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0632      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.958       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.77        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 5.67e+05      |\n",
            "|    total_cost           | 2.79e+03      |\n",
            "|    total_reward         | 4.67e+05      |\n",
            "|    total_reward_pct     | 467           |\n",
            "|    total_trades         | 2491          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 477           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 64            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00036443895 |\n",
            "|    clip_fraction        | 0.000244      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.0337        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.11          |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.000496     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 3.12          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 6.03e+05    |\n",
            "|    total_cost           | 3.07e+03    |\n",
            "|    total_reward         | 5.03e+05    |\n",
            "|    total_reward_pct     | 503         |\n",
            "|    total_trades         | 2491        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003415836 |\n",
            "|    clip_fraction        | 0.00664     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0532      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.000968   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.51        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009765526 |\n",
            "|    clip_fraction        | 0.022       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0201      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.42        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00157    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 4.32        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.27e+05     |\n",
            "|    total_cost           | 2.63e+03     |\n",
            "|    total_reward         | 5.27e+05     |\n",
            "|    total_reward_pct     | 527          |\n",
            "|    total_trades         | 2499         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006477011 |\n",
            "|    clip_fraction        | 0.00786      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.112        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.887        |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.000993    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.57e+05     |\n",
            "|    total_cost           | 2.51e+03     |\n",
            "|    total_reward         | 4.57e+05     |\n",
            "|    total_reward_pct     | 457          |\n",
            "|    total_trades         | 2500         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010225922 |\n",
            "|    clip_fraction        | 0.0085       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0749       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.41         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 3.69         |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 50\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 669880.85\n",
            "total_reward: 569880.85\n",
            "total_cost: 2293.08\n",
            "total_trades: 2491\n",
            "Sharpe: 0.916\n",
            "=================================\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.7e+05      |\n",
            "|    total_cost           | 2.29e+03     |\n",
            "|    total_reward         | 5.7e+05      |\n",
            "|    total_reward_pct     | 570          |\n",
            "|    total_trades         | 2491         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020263186 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0475       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.29         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.001       |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 3.65         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 6.87e+05      |\n",
            "|    total_cost           | 2.4e+03       |\n",
            "|    total_reward         | 5.87e+05      |\n",
            "|    total_reward_pct     | 587           |\n",
            "|    total_trades         | 2499          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 476           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 90            |\n",
            "|    total_timesteps      | 43008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00071507454 |\n",
            "|    clip_fraction        | 0.00264       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.0382        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 2.05          |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | -0.000255     |\n",
            "|    std                  | 0.997         |\n",
            "|    value_loss           | 4.85          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028688337 |\n",
            "|    clip_fraction        | 0.0063       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0399       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.03         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000535    |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 5.7          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 6.64e+05    |\n",
            "|    total_cost           | 2.01e+03    |\n",
            "|    total_reward         | 5.64e+05    |\n",
            "|    total_reward_pct     | 564         |\n",
            "|    total_trades         | 2492        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 477         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 98          |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000872418 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.0145      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.28        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000227   |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 2.55        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.79e+05     |\n",
            "|    total_cost           | 2.07e+03     |\n",
            "|    total_reward         | 5.79e+05     |\n",
            "|    total_reward_pct     | 579          |\n",
            "|    total_trades         | 2495         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025357683 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0321       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.78         |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.000383    |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 4.56         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 6.78e+05      |\n",
            "|    total_cost           | 2.07e+03      |\n",
            "|    total_reward         | 5.78e+05      |\n",
            "|    total_reward_pct     | 578           |\n",
            "|    total_trades         | 2498          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 475           |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 107           |\n",
            "|    total_timesteps      | 51200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00080818543 |\n",
            "|    clip_fraction        | 0.00259       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 0.0366        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.3           |\n",
            "|    n_updates            | 240           |\n",
            "|    policy_gradient_loss | -0.0013       |\n",
            "|    std                  | 0.991         |\n",
            "|    value_loss           | 4.78          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 6.9e+05     |\n",
            "|    total_cost           | 2.36e+03    |\n",
            "|    total_reward         | 5.9e+05     |\n",
            "|    total_reward_pct     | 590         |\n",
            "|    total_trades         | 2491        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 475         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005060239 |\n",
            "|    clip_fraction        | 0.0267      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.0285      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.37        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0035     |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 5.08        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 116           |\n",
            "|    total_timesteps      | 55296         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00045473906 |\n",
            "|    clip_fraction        | 0.00107       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 0.039         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 2.36          |\n",
            "|    n_updates            | 260           |\n",
            "|    policy_gradient_loss | -0.000262     |\n",
            "|    std                  | 0.99          |\n",
            "|    value_loss           | 5.48          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 6.72e+05      |\n",
            "|    total_cost           | 2.41e+03      |\n",
            "|    total_reward         | 5.72e+05      |\n",
            "|    total_reward_pct     | 572           |\n",
            "|    total_trades         | 2504          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 121           |\n",
            "|    total_timesteps      | 57344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034604486 |\n",
            "|    clip_fraction        | 0.000586      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | -0.00839      |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 2.35          |\n",
            "|    n_updates            | 270           |\n",
            "|    policy_gradient_loss | -0.000239     |\n",
            "|    std                  | 0.986         |\n",
            "|    value_loss           | 3.55          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.82e+05     |\n",
            "|    total_cost           | 2.28e+03     |\n",
            "|    total_reward         | 5.82e+05     |\n",
            "|    total_reward_pct     | 582          |\n",
            "|    total_trades         | 2490         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022680066 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0267       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.44         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.000264    |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 3.7          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 7.18e+05      |\n",
            "|    total_cost           | 2.03e+03      |\n",
            "|    total_reward         | 6.18e+05      |\n",
            "|    total_reward_pct     | 618           |\n",
            "|    total_trades         | 2496          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 472           |\n",
            "|    iterations           | 30            |\n",
            "|    time_elapsed         | 130           |\n",
            "|    total_timesteps      | 61440         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00087924127 |\n",
            "|    clip_fraction        | 0.00635       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 0.0299        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 2.31          |\n",
            "|    n_updates            | 290           |\n",
            "|    policy_gradient_loss | -0.000601     |\n",
            "|    std                  | 0.988         |\n",
            "|    value_loss           | 4.86          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.83e+05     |\n",
            "|    total_cost           | 1.92e+03     |\n",
            "|    total_reward         | 5.83e+05     |\n",
            "|    total_reward_pct     | 583          |\n",
            "|    total_trades         | 2496         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 134          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010620623 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0178       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.95         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000762    |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 5.77         |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 60\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 699622.20\n",
            "total_reward: 599622.20\n",
            "total_cost: 1818.60\n",
            "total_trades: 2501\n",
            "Sharpe: 0.923\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 7e+05       |\n",
            "|    total_cost           | 1.82e+03    |\n",
            "|    total_reward         | 6e+05       |\n",
            "|    total_reward_pct     | 600         |\n",
            "|    total_trades         | 2501        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 470         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 139         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004312874 |\n",
            "|    clip_fraction        | 0.00688     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.0241      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.91        |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    std                  | 0.986       |\n",
            "|    value_loss           | 5.1         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 143          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026027502 |\n",
            "|    clip_fraction        | 0.00474      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0265       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.85         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000828    |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 5.9          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.95e+05     |\n",
            "|    total_cost           | 1.51e+03     |\n",
            "|    total_reward         | 5.95e+05     |\n",
            "|    total_reward_pct     | 595          |\n",
            "|    total_trades         | 2503         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 148          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027154104 |\n",
            "|    clip_fraction        | 0.00796      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0358       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.23         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000754    |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 2.54         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 7.2e+05      |\n",
            "|    total_cost           | 1.43e+03     |\n",
            "|    total_reward         | 6.2e+05      |\n",
            "|    total_reward_pct     | 620          |\n",
            "|    total_trades         | 2505         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064976662 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0299       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.58         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    std                  | 0.981        |\n",
            "|    value_loss           | 5.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.89e+05     |\n",
            "|    total_cost           | 1.74e+03     |\n",
            "|    total_reward         | 5.89e+05     |\n",
            "|    total_reward_pct     | 589          |\n",
            "|    total_trades         | 2506         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054869573 |\n",
            "|    clip_fraction        | 0.00894      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0288       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.2          |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00093     |\n",
            "|    std                  | 0.982        |\n",
            "|    value_loss           | 5.6          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.82e+05     |\n",
            "|    total_cost           | 1.91e+03     |\n",
            "|    total_reward         | 5.82e+05     |\n",
            "|    total_reward_pct     | 582          |\n",
            "|    total_trades         | 2494         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 161          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016466575 |\n",
            "|    clip_fraction        | 0.00742      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0387       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.34         |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    std                  | 0.98         |\n",
            "|    value_loss           | 5.11         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 166         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003011226 |\n",
            "|    clip_fraction        | 0.00278     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.027       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.27        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.000143   |\n",
            "|    std                  | 0.986       |\n",
            "|    value_loss           | 5.6         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.85e+05     |\n",
            "|    total_cost           | 1.8e+03      |\n",
            "|    total_reward         | 5.85e+05     |\n",
            "|    total_reward_pct     | 585          |\n",
            "|    total_trades         | 2500         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017625319 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -0.00289     |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.31         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 2.98         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| environment/            |                |\n",
            "|    portfolio_value      | 6.88e+05       |\n",
            "|    total_cost           | 1.49e+03       |\n",
            "|    total_reward         | 5.88e+05       |\n",
            "|    total_reward_pct     | 588            |\n",
            "|    total_trades         | 2501           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 468            |\n",
            "|    iterations           | 40             |\n",
            "|    time_elapsed         | 174            |\n",
            "|    total_timesteps      | 81920          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -0.00010869058 |\n",
            "|    clip_fraction        | 0.00103        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.4           |\n",
            "|    explained_variance   | 0.0306         |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 3.1            |\n",
            "|    n_updates            | 390            |\n",
            "|    policy_gradient_loss | -0.000473      |\n",
            "|    std                  | 0.985          |\n",
            "|    value_loss           | 4.64           |\n",
            "--------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fwLOGD0kYX"
      },
      "source": [
        "## TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ElntVCrq2-",
        "outputId": "ba1372c9-c9ba-47e1-9acc-bf6a5d35d538"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 128, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.0003}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl2tYmwyruVi",
        "outputId": "f9a9da96-4161-4f39-c638-67966ed752e6"
      },
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/td3/td3_1\n",
            "day: 2515, episode: 70\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 859765.38\n",
            "total_reward: 759765.38\n",
            "total_cost: 99.90\n",
            "total_trades: 2515\n",
            "Sharpe: 0.990\n",
            "=================================\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 58       |\n",
            "|    time_elapsed     | 172      |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 873      |\n",
            "|    critic_loss      | 1.96e+03 |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 7548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 48       |\n",
            "|    time_elapsed     | 411      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 716      |\n",
            "|    critic_loss      | 586      |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 17612    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 46       |\n",
            "|    time_elapsed     | 655      |\n",
            "|    total timesteps  | 30192    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 559      |\n",
            "|    critic_loss      | 291      |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 27676    |\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLfiknV90ojP"
      },
      "source": [
        "## SAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aheRRAnryLM",
        "outputId": "376c5915-34e5-469f-fb50-688dfd2a26c0"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.00003,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 3e-05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN_hr4Ysr16C",
        "outputId": "3a57dcdc-4a9e-4d6f-e6d3-60477c891333"
      },
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/sac/sac_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 41       |\n",
            "|    time_elapsed     | 241      |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 118      |\n",
            "|    critic_loss      | 5.12     |\n",
            "|    ent_coef         | 0.135    |\n",
            "|    ent_coef_loss    | 18.7     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 9963     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 41       |\n",
            "|    time_elapsed     | 490      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 117      |\n",
            "|    critic_loss      | 3.2      |\n",
            "|    ent_coef         | 0.182    |\n",
            "|    ent_coef_loss    | 16.1     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 20027    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 90\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 859765.38\n",
            "total_reward: 759765.38\n",
            "total_cost: 99.90\n",
            "total_trades: 2515\n",
            "Sharpe: 0.990\n",
            "=================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msYBglNU0tcf"
      },
      "source": [
        "#from finrl.trade.backtest import backtest_stats, baseline_stats, backtest_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAaAwPV90yRa"
      },
      "source": [
        "from finrl.trade.backtest import backtest_stats"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMuQRHCU0zq8"
      },
      "source": [
        "from finrl.trade.backtest import backtest_plot"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "gdF94oka1DpC",
        "outputId": "7dcec3fa-88c1-4e78-fd80-270b2effc1da"
      },
      "source": [
        "trade.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>38.722500</td>\n",
              "      <td>39.712502</td>\n",
              "      <td>38.557499</td>\n",
              "      <td>38.505024</td>\n",
              "      <td>148158800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.016889</td>\n",
              "      <td>44.505522</td>\n",
              "      <td>35.444587</td>\n",
              "      <td>37.867340</td>\n",
              "      <td>-91.571542</td>\n",
              "      <td>42.250808</td>\n",
              "      <td>41.225720</td>\n",
              "      <td>46.488189</td>\n",
              "      <td>26.255061</td>\n",
              "      <td>39.177500</td>\n",
              "      <td>39.975055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.517199</td>\n",
              "      <td>-6.875741</td>\n",
              "      <td>-0.761653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>35.994999</td>\n",
              "      <td>36.430000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>34.669640</td>\n",
              "      <td>365248800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.199742</td>\n",
              "      <td>43.911981</td>\n",
              "      <td>34.998697</td>\n",
              "      <td>32.751902</td>\n",
              "      <td>-177.958729</td>\n",
              "      <td>55.246973</td>\n",
              "      <td>40.808453</td>\n",
              "      <td>46.157722</td>\n",
              "      <td>11.997918</td>\n",
              "      <td>37.358749</td>\n",
              "      <td>39.455339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.050853</td>\n",
              "      <td>-7.085639</td>\n",
              "      <td>-0.763467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>36.132500</td>\n",
              "      <td>37.137501</td>\n",
              "      <td>35.950001</td>\n",
              "      <td>36.149662</td>\n",
              "      <td>234428400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.199870</td>\n",
              "      <td>43.454764</td>\n",
              "      <td>34.762716</td>\n",
              "      <td>36.192789</td>\n",
              "      <td>-139.717644</td>\n",
              "      <td>47.060632</td>\n",
              "      <td>40.502857</td>\n",
              "      <td>45.854029</td>\n",
              "      <td>12.988335</td>\n",
              "      <td>36.063749</td>\n",
              "      <td>39.108740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.077832</td>\n",
              "      <td>-7.044321</td>\n",
              "      <td>-0.766086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>37.174999</td>\n",
              "      <td>37.207500</td>\n",
              "      <td>36.474998</td>\n",
              "      <td>36.069202</td>\n",
              "      <td>219111200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.181318</td>\n",
              "      <td>43.003009</td>\n",
              "      <td>34.561260</td>\n",
              "      <td>36.088942</td>\n",
              "      <td>-122.742724</td>\n",
              "      <td>46.245025</td>\n",
              "      <td>40.266752</td>\n",
              "      <td>45.536440</td>\n",
              "      <td>13.030644</td>\n",
              "      <td>36.653749</td>\n",
              "      <td>38.782134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.884737</td>\n",
              "      <td>-6.900339</td>\n",
              "      <td>-0.767321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>37.389999</td>\n",
              "      <td>37.955002</td>\n",
              "      <td>37.130001</td>\n",
              "      <td>36.756794</td>\n",
              "      <td>164101200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.087075</td>\n",
              "      <td>42.733426</td>\n",
              "      <td>34.398295</td>\n",
              "      <td>37.670002</td>\n",
              "      <td>-95.013556</td>\n",
              "      <td>37.537680</td>\n",
              "      <td>40.055192</td>\n",
              "      <td>45.272874</td>\n",
              "      <td>18.339891</td>\n",
              "      <td>37.282499</td>\n",
              "      <td>38.565861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.041614</td>\n",
              "      <td>-6.589742</td>\n",
              "      <td>-0.759067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high  ...       wr_10       dma      trix\n",
              "0  2019-01-02  38.722500  39.712502  ...   64.517199 -6.875741 -0.761653\n",
              "1  2019-01-03  35.994999  36.430000  ...  113.050853 -7.085639 -0.763467\n",
              "2  2019-01-04  36.132500  37.137501  ...   87.077832 -7.044321 -0.766086\n",
              "3  2019-01-07  37.174999  37.207500  ...   86.884737 -6.900339 -0.767321\n",
              "4  2019-01-08  37.389999  37.955002  ...   71.041614 -6.589742 -0.759067\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yer7WCBW2OdO"
      },
      "source": [
        "## errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "VOjnbv1_1jqy",
        "outputId": "41d630f6-b90b-4af1-af4b-017a4261f7ea"
      },
      "source": [
        "## make a prediction and get the account value change\n",
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_sac,\n",
        "                                           trade_data  = trade,\n",
        "                                           test_env = env_trade,\n",
        "                                           test_obs = obs_trade)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-52459e78ba62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                            \u001b[0mtrade_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrade\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                            \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_trade\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                            test_obs = obs_trade)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: DRL_prediction() got an unexpected keyword argument 'trade_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "TLgZ33eA1FaV",
        "outputId": "f4ebdc99-a545-4c79-fd4e-96461736a147"
      },
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-24958daad3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackTestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BackTestStats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JThQjS-o2SUY"
      },
      "source": [
        "## back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PtOThIK2RQd"
      },
      "source": [
        "e_trade_gym.hmax = 2500"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "XaRz4-6H2Xx6",
        "outputId": "9b3ee210-2194-4de5-cc4b-28c0bd6d0dc1"
      },
      "source": [
        "print(len(e_trade_gym.dates))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1fa7e324196e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_trade_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'StockTradingEnv' object has no attribute 'dates'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6ucMSb2c3P",
        "outputId": "f3a3ae9c-2d9e-4c9d-e87e-c6a7b4cc799f"
      },
      "source": [
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_sac,environment = e_trade_gym)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JPU8foMl2nPh",
        "outputId": "743a9c6e-511e-4130-cfe8-21b766b0e557"
      },
      "source": [
        "df_account_value.head(50)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>account_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>90315.276518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>94167.094637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>93957.614002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>95748.102405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2019-01-09</td>\n",
              "      <td>97373.496509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2019-01-10</td>\n",
              "      <td>97684.622776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2019-01-11</td>\n",
              "      <td>96725.893757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2019-01-14</td>\n",
              "      <td>95271.901706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2019-01-15</td>\n",
              "      <td>97221.126987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2019-01-16</td>\n",
              "      <td>98408.425190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>98992.543125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>99602.070881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2019-01-22</td>\n",
              "      <td>97367.168888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2019-01-23</td>\n",
              "      <td>97760.812504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2019-01-24</td>\n",
              "      <td>96986.200382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2019-01-25</td>\n",
              "      <td>100198.893726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2019-01-28</td>\n",
              "      <td>99271.922016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2019-01-29</td>\n",
              "      <td>98243.350757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2019-01-30</td>\n",
              "      <td>104954.473758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2019-01-31</td>\n",
              "      <td>105710.053348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>105760.853122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2019-02-04</td>\n",
              "      <td>108764.019748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2019-02-05</td>\n",
              "      <td>110624.360325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2019-02-06</td>\n",
              "      <td>110662.445255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2019-02-07</td>\n",
              "      <td>108567.207874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2019-02-08</td>\n",
              "      <td>108694.723850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2019-02-11</td>\n",
              "      <td>108069.829014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2019-02-12</td>\n",
              "      <td>109000.813846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2019-02-13</td>\n",
              "      <td>108548.066074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2019-02-14</td>\n",
              "      <td>108943.418247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2019-02-15</td>\n",
              "      <td>108701.091205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2019-02-19</td>\n",
              "      <td>109026.313068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-02-20</td>\n",
              "      <td>109727.725437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-02-21</td>\n",
              "      <td>109109.197956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-02-22</td>\n",
              "      <td>110327.121052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-02-25</td>\n",
              "      <td>111130.540241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-02-26</td>\n",
              "      <td>111194.293262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2019-02-27</td>\n",
              "      <td>111538.637058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>110441.892383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2019-03-01</td>\n",
              "      <td>111602.400013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2019-03-04</td>\n",
              "      <td>112163.521961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2019-03-05</td>\n",
              "      <td>111959.468586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2019-03-06</td>\n",
              "      <td>111315.461750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2019-03-07</td>\n",
              "      <td>110027.408344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2019-03-08</td>\n",
              "      <td>110288.847385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2019-03-11</td>\n",
              "      <td>114108.346714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2019-03-12</td>\n",
              "      <td>115390.022831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2019-03-13</td>\n",
              "      <td>115538.877538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2019-03-14</td>\n",
              "      <td>116756.388467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  account_value\n",
              "0   2019-01-02  100000.000000\n",
              "1   2019-01-03   90315.276518\n",
              "2   2019-01-04   94167.094637\n",
              "3   2019-01-07   93957.614002\n",
              "4   2019-01-08   95748.102405\n",
              "5   2019-01-09   97373.496509\n",
              "6   2019-01-10   97684.622776\n",
              "7   2019-01-11   96725.893757\n",
              "8   2019-01-14   95271.901706\n",
              "9   2019-01-15   97221.126987\n",
              "10  2019-01-16   98408.425190\n",
              "11  2019-01-17   98992.543125\n",
              "12  2019-01-18   99602.070881\n",
              "13  2019-01-22   97367.168888\n",
              "14  2019-01-23   97760.812504\n",
              "15  2019-01-24   96986.200382\n",
              "16  2019-01-25  100198.893726\n",
              "17  2019-01-28   99271.922016\n",
              "18  2019-01-29   98243.350757\n",
              "19  2019-01-30  104954.473758\n",
              "20  2019-01-31  105710.053348\n",
              "21  2019-02-01  105760.853122\n",
              "22  2019-02-04  108764.019748\n",
              "23  2019-02-05  110624.360325\n",
              "24  2019-02-06  110662.445255\n",
              "25  2019-02-07  108567.207874\n",
              "26  2019-02-08  108694.723850\n",
              "27  2019-02-11  108069.829014\n",
              "28  2019-02-12  109000.813846\n",
              "29  2019-02-13  108548.066074\n",
              "30  2019-02-14  108943.418247\n",
              "31  2019-02-15  108701.091205\n",
              "32  2019-02-19  109026.313068\n",
              "33  2019-02-20  109727.725437\n",
              "34  2019-02-21  109109.197956\n",
              "35  2019-02-22  110327.121052\n",
              "36  2019-02-25  111130.540241\n",
              "37  2019-02-26  111194.293262\n",
              "38  2019-02-27  111538.637058\n",
              "39  2019-02-28  110441.892383\n",
              "40  2019-03-01  111602.400013\n",
              "41  2019-03-04  112163.521961\n",
              "42  2019-03-05  111959.468586\n",
              "43  2019-03-06  111315.461750\n",
              "44  2019-03-07  110027.408344\n",
              "45  2019-03-08  110288.847385\n",
              "46  2019-03-11  114108.346714\n",
              "47  2019-03-12  115390.022831\n",
              "48  2019-03-13  115538.877538\n",
              "49  2019-03-14  116756.388467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "JciY6fSC20ag",
        "outputId": "b46eae22-1247-4103-b4ed-9e75bd36a263"
      },
      "source": [
        "\n",
        "print(\"==============Get Backtest Results===========\")\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value, value_col_name = 'total_assets')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_assets'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-521b8be91ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============Get Backtest Results===========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'total_assets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mbacktest_stats\u001b[0;34m(account_value, value_col_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbacktest_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"account_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdr_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_col_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     perf_stats_all = timeseries.perf_stats(\n\u001b[1;32m     34\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdr_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mget_daily_return\u001b[0;34m(df, value_col_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_daily_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"account_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue_col_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_assets'"
          ]
        }
      ]
    }
  ]
}