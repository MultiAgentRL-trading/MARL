{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppleStock_usingFINRL_5_includingBT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U4XebRCpdUo",
        "outputId": "5d91a2e8-244b-4a74-f622-0ea9ca1c3fda"
      },
      "source": [
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-_fli_hyb\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-_fli_hyb\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (1.1.5)\n",
            "Collecting stockstats\n",
            "  Downloading https://files.pythonhosted.org/packages/32/41/d3828c5bc0a262cb3112a4024108a3b019c183fa3b3078bff34bf25abf91/stockstats-0.3.2-py2.py3-none-any.whl\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.22.2.post1)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/97/f6da6fcaa96934832c02acf95a32309cfa8646b010221f6c7a14bfcf40d0/stable_baselines3-0.11.1-py3-none-any.whl (152kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (54.0.0)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.0) (0.36.2)\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-reugod3l/pyfolio\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-reugod3l/pyfolio\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.3.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->finrl==0.3.0) (2018.9)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/43/27/31803df15173ab341fe7548c14154b54227dfd8f630daa09a1c6e7db52f7/int_date-0.1.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.0) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.0) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/88/b25778f17e5320c1c58f8c5060fb5b037288e162bd7554c30799e9ea90db/lxml-4.6.2-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.0) (0.10.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (5.4.8)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (7.0.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (0.2.6)\n",
            "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (2.4.1)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.0) (4.1.2.30)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (20.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.15.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (8.7.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.0) (0.7.1)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (5.5.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.11.1)\n",
            "Collecting empyrical>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance->finrl==0.3.0) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->stable-baselines3[extra]->finrl==0.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.12.4)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.8.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.0) (0.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]->finrl==0.3.0) (3.4.1)\n",
            "Building wheels for collected packages: finrl, yfinance, pyfolio, empyrical\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.0-cp37-none-any.whl size=38673 sha256=fa485ab8e9f3e5d4f9bfd2d566a35d5b83425e93b5ae40d46bd7a1313dabd1d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m2xkemo4/wheels/9c/19/bf/c644def96612df1ad42c94d5304966797eaa3221dffc5efe0b\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=121c4d1cac5934615c2d01ccf8cca0a75c820a69459241e192855ac458ba7edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-cp37-none-any.whl size=75764 sha256=af3170517cc59e1a0bf05bb2f31df6cfe5819609c5a8cb21851abbdf9c967ec3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m2xkemo4/wheels/43/ce/d9/6752fb6e03205408773235435205a0519d2c608a94f1976e56\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-cp37-none-any.whl size=39764 sha256=e3f71540f07910e436fd4cdd41301ae8f40d2ade0409eb5227b37d76e476e6f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
            "Successfully built finrl yfinance pyfolio empyrical\n",
            "Installing collected packages: int-date, stockstats, lxml, yfinance, stable-baselines3, empyrical, pyfolio, finrl\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed empyrical-0.5.5 finrl-0.3.0 int-date-0.1.8 lxml-4.6.2 pyfolio-0.9.2+75.g4b901f6 stable-baselines3-0.11.1 stockstats-0.3.2 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sV6EPYwpjDe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_stocktrading import StockTradingEnv\n",
        "from finrl.model.models import DRLAgent\n",
        "#from finrl.trade.backtest import backtest_stats, baseline_stats, backtest_plot\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfg_jKazpugT"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPuiNP4yp5BY"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8MZ8GDTap_Zs",
        "outputId": "39de20db-25b6-4637-89af-24012c1fb798"
      },
      "source": [
        "# from config.py start_date is a string\n",
        "config.START_DATE"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2000-01-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tpnkSjL4qAsJ",
        "outputId": "19096f3d-f985-41ff-fecd-9bf03743d87d"
      },
      "source": [
        "# from config.py end_date is a string\n",
        "config.END_DATE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2021-01-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCG-seqqHA-",
        "outputId": "6f251976-920d-4519-ae42-1dacc4b5101a"
      },
      "source": [
        "# Download and save the data in a pandas DataFrame:\n",
        "data_df = YahooDownloader(start_date = '2009-01-01',\n",
        "                          end_date = '2021-01-01',\n",
        "                          ticker_list = ['AAPL']).fetch_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3021, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUrtPNjYqLFv",
        "outputId": "78863ee9-f636-4644-b6c3-8da15eed1420"
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3021, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9CxM9RIlqMdW",
        "outputId": "e37fd175-581c-438d-a462-0744f973f6b0"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.909563</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.861573</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223571</td>\n",
              "      <td>2.799739</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.851728</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high       low     close      volume   tic  day\n",
              "0  2009-01-02  3.067143  3.251429  3.041429  2.791740   746015200  AAPL    4\n",
              "1  2009-01-05  3.327500  3.435000  3.311071  2.909563  1181608400  AAPL    0\n",
              "2  2009-01-06  3.426786  3.470357  3.299643  2.861573  1289310400  AAPL    1\n",
              "3  2009-01-07  3.278929  3.303571  3.223571  2.799739   753048800  AAPL    2\n",
              "4  2009-01-08  3.229643  3.326786  3.215714  2.851728   673500800  AAPL    3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ehKHtyeqVRl",
        "outputId": "eec8746d-f488-459d-8d53-45e60006e48c"
      },
      "source": [
        "## we store the stockstats technical indicator column names in config.py\n",
        "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bonWJGypqYw3",
        "outputId": "9450df67-00db-4243-b01e-b9764e305f20"
      },
      "source": [
        "## user can add more technical indicators\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IU1z142qcF7",
        "outputId": "041efbec-a714-47c3-b377-ab0ce8bbe372"
      },
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = tech_indicator_list,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "data_df = fe.preprocess_data(data_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "TckZGWrYqfUQ",
        "outputId": "be2bb5bb-8413-40bd-f3ae-b7314005ccef"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.017278</td>\n",
              "      <td>2.684025</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>-6.299850</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>2.791740</td>\n",
              "      <td>1.0</td>\n",
              "      <td>218.899551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.909563</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002643</td>\n",
              "      <td>3.017278</td>\n",
              "      <td>2.684025</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>-15.368278</td>\n",
              "      <td>3.197322</td>\n",
              "      <td>2.850651</td>\n",
              "      <td>2.0</td>\n",
              "      <td>133.505133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.861573</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001880</td>\n",
              "      <td>2.972787</td>\n",
              "      <td>2.735796</td>\n",
              "      <td>70.355711</td>\n",
              "      <td>46.771878</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>-24.222698</td>\n",
              "      <td>3.377143</td>\n",
              "      <td>2.854292</td>\n",
              "      <td>3.0</td>\n",
              "      <td>141.931537</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223571</td>\n",
              "      <td>2.799739</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.000746</td>\n",
              "      <td>2.951725</td>\n",
              "      <td>2.729582</td>\n",
              "      <td>50.429389</td>\n",
              "      <td>-29.777993</td>\n",
              "      <td>43.607834</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>-34.930948</td>\n",
              "      <td>3.352857</td>\n",
              "      <td>2.840654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>156.347447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.195393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.851728</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000088</td>\n",
              "      <td>2.939568</td>\n",
              "      <td>2.746169</td>\n",
              "      <td>60.227126</td>\n",
              "      <td>-9.019317</td>\n",
              "      <td>48.357918</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>-38.029528</td>\n",
              "      <td>3.254286</td>\n",
              "      <td>2.842869</td>\n",
              "      <td>5.0</td>\n",
              "      <td>144.226688</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high  ...       wr_10  dma      trix\n",
              "0  2009-01-02  3.067143  3.251429  ...  218.899551  0.0  0.670734\n",
              "1  2009-01-05  3.327500  3.435000  ...  133.505133  0.0  0.670734\n",
              "2  2009-01-06  3.426786  3.470357  ...  141.931537  0.0  0.391304\n",
              "3  2009-01-07  3.278929  3.303571  ...  156.347447  0.0  0.195393\n",
              "4  2009-01-08  3.229643  3.326786  ...  144.226688  0.0  0.125125\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsYcJ5Ewqkau"
      },
      "source": [
        "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
        "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
        "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pDuAROrqmWY",
        "outputId": "b800874d-ad5c-44d0-d72b-c88c85e90301"
      },
      "source": [
        "\n",
        "## we store the stockstats technical indicator column names in config.py\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma',\n",
              " 'kdjk',\n",
              " 'open_2_sma',\n",
              " 'boll',\n",
              " 'close_10.0_le_5_c',\n",
              " 'wr_10',\n",
              " 'dma',\n",
              " 'trix']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55XH4mfLqvPG",
        "outputId": "6d4bbe2a-0d74-4eea-b078-3c31612d5088"
      },
      "source": [
        "\n",
        "# the stock dimension is 1, because we only use the price data of AAPL.\n",
        "len(train.tic.unique())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMnVqQKqywu",
        "outputId": "49b0e481-6197-476b-dcd0-617adcb08d97"
      },
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stock Dimension: 1, State Space: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxWZIhhsq0Ga"
      },
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 100000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4\n",
        "    \n",
        "}\n",
        "\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udKmycKZq6KS",
        "outputId": "f86bca4d-102c-4750-a647-3c9d162e3f0f"
      },
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-PYHx7eq-Ox"
      },
      "source": [
        "\n",
        "agent = DRLAgent(env = env_train)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztFgaddl0W3T"
      },
      "source": [
        "## A2C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c22Ml99xrB49",
        "outputId": "7da96d0c-2d16-401f-a5c2-db392a38c629"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbz3mCV4rD54",
        "outputId": "9e742222-0e36-4b89-c080-25d8337a305a"
      },
      "source": [
        "\n",
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=50000)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/a2c/a2c_1\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 135       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.44     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 0.000711  |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.93e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 176       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.45     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -0.593    |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.216     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 195      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.335   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.0732   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 207      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.354   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.039    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.252    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.121    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.28e+05 |\n",
            "|    total_cost         | 3.39e+03 |\n",
            "|    total_reward       | 1.28e+05 |\n",
            "|    total_reward_pct   | 128      |\n",
            "|    total_trades       | 2493     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.0536   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.00266  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -0.0183  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.661    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.37     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -0.0432  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.637    |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.336    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.522   |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.181    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -0.996   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.77     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.12e+05 |\n",
            "|    total_cost         | 3.42e+03 |\n",
            "|    total_reward       | 2.12e+05 |\n",
            "|    total_reward_pct   | 212      |\n",
            "|    total_trades       | 2487     |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.0333   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.000681 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 234      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.146   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0133   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 235      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | -0.288   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.785    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.571    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 236      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.0748  |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.00233  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 238      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.297   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.307    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.33e+05 |\n",
            "|    total_cost         | 3.39e+03 |\n",
            "|    total_reward       | 1.33e+05 |\n",
            "|    total_reward_pct   | 133      |\n",
            "|    total_trades       | 2485     |\n",
            "| time/                 |          |\n",
            "|    fps                | 238      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.00777  |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 2.54e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 239      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.00805 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 7.42e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 240      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.00639 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.000251 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 240      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.000847 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 5.9e-07  |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.48     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -0.00817  |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 5.34e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 1.15e+05  |\n",
            "|    total_cost         | 3.08e+03  |\n",
            "|    total_reward       | 1.48e+04  |\n",
            "|    total_reward_pct   | 14.8      |\n",
            "|    total_trades       | 2346      |\n",
            "| time/                 |           |\n",
            "|    fps                | 241       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.48     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 0.00593   |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 3.26e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 242      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.00464 |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 2.23e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 242       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.5      |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -0.000875 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 7.05e-07  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 243      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 49       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0107   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 5.74e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 243      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.227    |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.0148   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 9.86e+04  |\n",
            "|    total_cost         | 2.93e+03  |\n",
            "|    total_reward       | -1.39e+03 |\n",
            "|    total_reward_pct   | -1.39     |\n",
            "|    total_trades       | 2197      |\n",
            "| time/                 |           |\n",
            "|    fps                | 243       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.53     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | -0.0138   |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.000156  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 243      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.53    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.0324   |\n",
            "|    std                | 1.12     |\n",
            "|    value_loss         | 0.000552 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 244      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.54    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | -0.00107 |\n",
            "|    std                | 1.13     |\n",
            "|    value_loss         | 1.04e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 244      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 59       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.55    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.00329  |\n",
            "|    std                | 1.14     |\n",
            "|    value_loss         | 2.38e-05 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.56     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | -0.00959  |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 4.44e-05  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 1.04e+05  |\n",
            "|    total_cost         | 2.62e+03  |\n",
            "|    total_reward       | 3.61e+03  |\n",
            "|    total_reward_pct   | 3.61      |\n",
            "|    total_trades       | 2129      |\n",
            "| time/                 |           |\n",
            "|    fps                | 244       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.57     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 0.00147   |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 1.66e-06  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 245       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.58     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 0.000159  |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 2.38e-08  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 67       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.6     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.00791  |\n",
            "|    std                | 1.2      |\n",
            "|    value_loss         | 1.78e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.61    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.0187   |\n",
            "|    std                | 1.21     |\n",
            "|    value_loss         | 0.000278 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 71       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.62    |\n",
            "|    explained_variance | 2.38e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.0447   |\n",
            "|    std                | 1.23     |\n",
            "|    value_loss         | 0.00121  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 1.03e+05 |\n",
            "|    total_cost         | 2.99e+03 |\n",
            "|    total_reward       | 2.98e+03 |\n",
            "|    total_reward_pct   | 2.98     |\n",
            "|    total_trades       | 2070     |\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 73       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.63    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.158   |\n",
            "|    std                | 1.24     |\n",
            "|    value_loss         | 0.0176   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 246       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.63     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 0.645     |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 0.373     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 246       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.64     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 0.378     |\n",
            "|    std                | 1.24      |\n",
            "|    value_loss         | 0.0796    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -0.938   |\n",
            "|    std                | 1.24     |\n",
            "|    value_loss         | 0.346    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 81       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0.181    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -0.824   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.445    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.5e+05  |\n",
            "|    total_cost         | 3.69e+03 |\n",
            "|    total_reward       | 2.5e+05  |\n",
            "|    total_reward_pct   | 250      |\n",
            "|    total_trades       | 2502     |\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | -2.4     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | 0.876    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.275    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0.107    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | 0.252    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.0712   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 87       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | -0.149   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | 0.575    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.256    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 89       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0.0676   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | -0.829   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.277    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 246      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0.721    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | -0.182   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.0202   |\n",
            "------------------------------------\n",
            "day: 2515, episode: 10\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 458954.31\n",
            "total_reward: 358954.31\n",
            "total_cost: 3703.33\n",
            "total_trades: 2497\n",
            "Sharpe: 0.823\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.59e+05 |\n",
            "|    total_cost         | 3.7e+03  |\n",
            "|    total_reward       | 3.59e+05 |\n",
            "|    total_reward_pct   | 359      |\n",
            "|    total_trades       | 2497     |\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 93       |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | -0.0865  |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.0111   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 95       |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0216  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | -1.04    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.796    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | 0.185    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.028    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | -0.343   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0485   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.0175   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | 4.59     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 11       |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 4.39e+05  |\n",
            "|    total_cost         | 3.72e+03  |\n",
            "|    total_reward       | 3.39e+05  |\n",
            "|    total_reward_pct   | 339       |\n",
            "|    total_trades       | 2490      |\n",
            "| time/                 |           |\n",
            "|    fps                | 247       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.65     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | -0.15     |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 0.0204    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 1.04     |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.981    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 247       |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.65     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 1.98      |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 1.38      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 108      |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.336    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | -0.917   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.724    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.156    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | 1.21     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.65     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.45e+05 |\n",
            "|    total_cost         | 3.72e+03 |\n",
            "|    total_reward       | 3.45e+05 |\n",
            "|    total_reward_pct   | 345      |\n",
            "|    total_trades       | 2489     |\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 5600     |\n",
            "|    time_elapsed       | 112      |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5599     |\n",
            "|    policy_loss        | 0.0228   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.000559 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.122    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | 0.727    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.311    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 116      |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.115    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | 0.00352  |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.0186   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 118      |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | -0.426   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.107    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6000     |\n",
            "|    time_elapsed       | 120      |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5999     |\n",
            "|    policy_loss        | -2.18    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 3.17     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 4.92e+05  |\n",
            "|    total_cost         | 3.62e+03  |\n",
            "|    total_reward       | 3.92e+05  |\n",
            "|    total_reward_pct   | 392       |\n",
            "|    total_trades       | 2501      |\n",
            "| time/                 |           |\n",
            "|    fps                | 248       |\n",
            "|    iterations         | 6100      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 30500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.64     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6099      |\n",
            "|    policy_loss        | -0.0759   |\n",
            "|    std                | 1.25      |\n",
            "|    value_loss         | 0.00626   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6200     |\n",
            "|    time_elapsed       | 124      |\n",
            "|    total_timesteps    | 31000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | -0.301   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6199     |\n",
            "|    policy_loss        | 0.935    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.276    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 126      |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | -0.164   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | -0.121   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.00738  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 128      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0385  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 1.32     |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 1.1      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6500     |\n",
            "|    time_elapsed       | 130      |\n",
            "|    total_timesteps    | 32500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6499     |\n",
            "|    policy_loss        | 2.54     |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 1.95     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 4.96e+05 |\n",
            "|    total_cost         | 3.69e+03 |\n",
            "|    total_reward       | 3.96e+05 |\n",
            "|    total_reward_pct   | 396      |\n",
            "|    total_trades       | 2493     |\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 132      |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.00136  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -0.0237  |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0109   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 134      |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | 0.0495   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0467   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.64    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | 0.929    |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.493    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 6900     |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 34500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6899     |\n",
            "|    policy_loss        | -0.154   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0917   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 248      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 140      |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.883   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | -5.65    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 4.07     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 5.05e+05 |\n",
            "|    total_cost         | 3.68e+03 |\n",
            "|    total_reward       | 4.05e+05 |\n",
            "|    total_reward_pct   | 405      |\n",
            "|    total_trades       | 2494     |\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 142      |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | -0.438   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.166    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7200     |\n",
            "|    time_elapsed       | 144      |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7199     |\n",
            "|    policy_loss        | 1.3      |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.69     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 146      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0698  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | 0.0705   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0865   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 148      |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.131   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | -0.731   |\n",
            "|    std                | 1.25     |\n",
            "|    value_loss         | 0.329    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 150      |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0459  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 0.299    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.139    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 5.65e+05 |\n",
            "|    total_cost         | 3.72e+03 |\n",
            "|    total_reward       | 4.65e+05 |\n",
            "|    total_reward_pct   | 465      |\n",
            "|    total_trades       | 2503     |\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 152      |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | -0.208   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.029    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 154      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.0282   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | 0.0454   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7800     |\n",
            "|    time_elapsed       | 156      |\n",
            "|    total_timesteps    | 39000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.0676   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7799     |\n",
            "|    policy_loss        | -0.0779  |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.22     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 158      |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.0337   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | -1.54    |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.941    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 160      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.158   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | 1.02     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.853    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 6.12e+05  |\n",
            "|    total_cost         | 3.73e+03  |\n",
            "|    total_reward       | 5.12e+05  |\n",
            "|    total_reward_pct   | 512       |\n",
            "|    total_trades       | 2507      |\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 162       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.65     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 0.218     |\n",
            "|    std                | 1.26      |\n",
            "|    value_loss         | 0.0296    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8200     |\n",
            "|    time_elapsed       | 164      |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0267  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8199     |\n",
            "|    policy_loss        | -0.0678  |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0267   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8300     |\n",
            "|    time_elapsed       | 166      |\n",
            "|    total_timesteps    | 41500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.242    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8299     |\n",
            "|    policy_loss        | 1.25     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.73     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8400     |\n",
            "|    time_elapsed       | 168      |\n",
            "|    total_timesteps    | 42000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0947  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8399     |\n",
            "|    policy_loss        | -0.162   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0885   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8500     |\n",
            "|    time_elapsed       | 170      |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.017   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8499     |\n",
            "|    policy_loss        | 2.72     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 2.57     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.49e+05 |\n",
            "|    total_cost         | 3.79e+03 |\n",
            "|    total_reward       | 5.49e+05 |\n",
            "|    total_reward_pct   | 549      |\n",
            "|    total_trades       | 2495     |\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 172      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | -0.527   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0951   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8700     |\n",
            "|    time_elapsed       | 174      |\n",
            "|    total_timesteps    | 43500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0.221    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8699     |\n",
            "|    policy_loss        | -1.4     |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 1.22     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8800     |\n",
            "|    time_elapsed       | 176      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8799     |\n",
            "|    policy_loss        | -0.162   |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.0734   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 178      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | -0.0539  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | -0.0538  |\n",
            "|    std                | 1.26     |\n",
            "|    value_loss         | 0.152    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 9000     |\n",
            "|    time_elapsed       | 180      |\n",
            "|    total_timesteps    | 45000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | -0.0164  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8999     |\n",
            "|    policy_loss        | 4.15     |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 13.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.5e+05  |\n",
            "|    total_cost         | 3.73e+03 |\n",
            "|    total_reward       | 5.5e+05  |\n",
            "|    total_reward_pct   | 550      |\n",
            "|    total_trades       | 2497     |\n",
            "| time/                 |          |\n",
            "|    fps                | 249      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 182      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.65    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -0.719   |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.301    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 183      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | -1.28    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 1.14     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9300     |\n",
            "|    time_elapsed       | 185      |\n",
            "|    total_timesteps    | 46500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9299     |\n",
            "|    policy_loss        | 0.498    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.161    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9400     |\n",
            "|    time_elapsed       | 187      |\n",
            "|    total_timesteps    | 47000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | -0.119   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9399     |\n",
            "|    policy_loss        | -0.575   |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.247    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 189      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | -0.0291  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | 0.615    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.187    |\n",
            "------------------------------------\n",
            "day: 2515, episode: 20\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 591080.77\n",
            "total_reward: 491080.77\n",
            "total_cost: 3764.38\n",
            "total_trades: 2502\n",
            "Sharpe: 0.934\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 5.91e+05 |\n",
            "|    total_cost         | 3.76e+03 |\n",
            "|    total_reward       | 4.91e+05 |\n",
            "|    total_reward_pct   | 491      |\n",
            "|    total_trades       | 2502     |\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 191      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | 0.162    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.0223   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 193      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | -1.02    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.348    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9800     |\n",
            "|    time_elapsed       | 195      |\n",
            "|    total_timesteps    | 49000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9799     |\n",
            "|    policy_loss        | 0.213    |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.171    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 9900     |\n",
            "|    time_elapsed       | 197      |\n",
            "|    total_timesteps    | 49500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9899     |\n",
            "|    policy_loss        | -0.842   |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.588    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 250      |\n",
            "|    iterations         | 10000    |\n",
            "|    time_elapsed       | 199      |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | -0.00589 |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9999     |\n",
            "|    policy_loss        | -0.0941  |\n",
            "|    std                | 1.27     |\n",
            "|    value_loss         | 0.2      |\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ELLp2220b6X"
      },
      "source": [
        "## DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzrsK3x-rTtT",
        "outputId": "722fac02-67dc-4d75-a66b-3ea021348c0c"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
        "\n",
        "\n",
        "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXclIEHFrdE_",
        "outputId": "fd6bddf3-2161-4074-c543-4c43fdb150b1"
      },
      "source": [
        "\n",
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ddpg/ddpg_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 117      |\n",
            "|    time_elapsed     | 85       |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 170      |\n",
            "|    critic_loss      | 971      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 7548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 103      |\n",
            "|    time_elapsed     | 195      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 74.4     |\n",
            "|    critic_loss      | 358      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 17612    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 30\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 859765.38\n",
            "total_reward: 759765.38\n",
            "total_cost: 99.90\n",
            "total_trades: 2515\n",
            "Sharpe: 0.990\n",
            "=================================\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 8.6e+05  |\n",
            "|    total_cost       | 99.9     |\n",
            "|    total_reward     | 7.6e+05  |\n",
            "|    total_reward_pct | 760      |\n",
            "|    total_trades     | 2515     |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 99       |\n",
            "|    time_elapsed     | 304      |\n",
            "|    total timesteps  | 30192    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 36.7     |\n",
            "|    critic_loss      | 149      |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 27676    |\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiLLVAXd0gaG"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FFZ0jfSris7",
        "outputId": "6731e3b0-9dca-4024-d64a-5d3b5b6191bf"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V168XyoTrltG",
        "outputId": "f5c392a6-578c-4b5c-ca5c-38856f08b410"
      },
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=80000)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ppo/ppo_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 391  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 5    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 1.32e+05     |\n",
            "|    total_cost           | 3.17e+03     |\n",
            "|    total_reward         | 3.16e+04     |\n",
            "|    total_reward_pct     | 31.6         |\n",
            "|    total_trades         | 2461         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029219335 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | -0.00702     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0037      |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.00994      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 1.25e+05     |\n",
            "|    total_cost           | 3.09e+03     |\n",
            "|    total_reward         | 2.5e+04      |\n",
            "|    total_reward_pct     | 25           |\n",
            "|    total_trades         | 2354         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058370954 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | -0.00523     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.00256      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 1.5e+05     |\n",
            "|    total_cost           | 3.19e+03    |\n",
            "|    total_reward         | 5.01e+04    |\n",
            "|    total_reward_pct     | 50.1        |\n",
            "|    total_trades         | 2472        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 6.27437e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -0.00533    |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.00443     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | 2.49e-05    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.0211      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 2.62e+05      |\n",
            "|    total_cost           | 3.1e+03       |\n",
            "|    total_reward         | 1.62e+05      |\n",
            "|    total_reward_pct     | 162           |\n",
            "|    total_trades         | 2489          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 340           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 30            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -0.0008186287 |\n",
            "|    clip_fraction        | 0.00356       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.0188        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.0306        |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.00174      |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.156         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 337           |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 36            |\n",
            "|    total_timesteps      | 12288         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00053018297 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -0.0284       |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.29          |\n",
            "|    n_updates            | 50            |\n",
            "|    policy_gradient_loss | -0.000392     |\n",
            "|    std                  | 0.997         |\n",
            "|    value_loss           | 0.71          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.58e+05     |\n",
            "|    total_cost           | 3.19e+03     |\n",
            "|    total_reward         | 1.58e+05     |\n",
            "|    total_reward_pct     | 158          |\n",
            "|    total_trades         | 2481         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 335          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047474424 |\n",
            "|    clip_fraction        | 0.00713      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.174        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.0991       |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.184        |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 40\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 329620.80\n",
            "total_reward: 229620.80\n",
            "total_cost: 3081.80\n",
            "total_trades: 2491\n",
            "Sharpe: 0.722\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 3.3e+05       |\n",
            "|    total_cost           | 3.08e+03      |\n",
            "|    total_reward         | 2.3e+05       |\n",
            "|    total_reward_pct     | 230           |\n",
            "|    total_trades         | 2491          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 334           |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 48            |\n",
            "|    total_timesteps      | 16384         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -5.186847e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.155         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.259         |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | -0.000282     |\n",
            "|    std                  | 0.997         |\n",
            "|    value_loss           | 0.607         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.82e+05     |\n",
            "|    total_cost           | 3.04e+03     |\n",
            "|    total_reward         | 1.82e+05     |\n",
            "|    total_reward_pct     | 182          |\n",
            "|    total_trades         | 2476         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 55           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027916078 |\n",
            "|    clip_fraction        | 0.00117      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0925       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.423        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.000867    |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.969        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 4.05e+05    |\n",
            "|    total_cost           | 2.7e+03     |\n",
            "|    total_reward         | 3.05e+05    |\n",
            "|    total_reward_pct     | 305         |\n",
            "|    total_trades         | 2493        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002062412 |\n",
            "|    clip_fraction        | 0.000195    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.163       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.317       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 0.88        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006538286 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0696       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.17         |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000929    |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 1.9          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.76e+05     |\n",
            "|    total_cost           | 2.51e+03     |\n",
            "|    total_reward         | 3.76e+05     |\n",
            "|    total_reward_pct     | 376          |\n",
            "|    total_trades         | 2485         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017505386 |\n",
            "|    clip_fraction        | 0.00796      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0378       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.782        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 1.5          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 4.9e+05     |\n",
            "|    total_cost           | 2.56e+03    |\n",
            "|    total_reward         | 3.9e+05     |\n",
            "|    total_reward_pct     | 390         |\n",
            "|    total_trades         | 2493        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003606032 |\n",
            "|    clip_fraction        | 0.00317     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0192      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.705       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.000855   |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 2.06        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 4.75e+05      |\n",
            "|    total_cost           | 2.56e+03      |\n",
            "|    total_reward         | 3.75e+05      |\n",
            "|    total_reward_pct     | 375           |\n",
            "|    total_trades         | 2500          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 331           |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 86            |\n",
            "|    total_timesteps      | 28672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00064671325 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.0546        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.47          |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -9.44e-05     |\n",
            "|    std                  | 0.996         |\n",
            "|    value_loss           | 2.36          |\n",
            "-------------------------------------------\n",
            "---------------------------------------\n",
            "| environment/            |           |\n",
            "|    portfolio_value      | 4.49e+05  |\n",
            "|    total_cost           | 2.01e+03  |\n",
            "|    total_reward         | 3.49e+05  |\n",
            "|    total_reward_pct     | 349       |\n",
            "|    total_trades         | 2505      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 331       |\n",
            "|    iterations           | 15        |\n",
            "|    time_elapsed         | 92        |\n",
            "|    total_timesteps      | 30720     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0023487 |\n",
            "|    clip_fraction        | 0.00645   |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.42     |\n",
            "|    explained_variance   | 0.0644    |\n",
            "|    learning_rate        | 0.0001    |\n",
            "|    loss                 | 1.12      |\n",
            "|    n_updates            | 140       |\n",
            "|    policy_gradient_loss | -0.00128  |\n",
            "|    std                  | 1         |\n",
            "|    value_loss           | 2.53      |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.6e+05      |\n",
            "|    total_cost           | 2.37e+03     |\n",
            "|    total_reward         | 4.6e+05      |\n",
            "|    total_reward_pct     | 460          |\n",
            "|    total_trades         | 2493         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021774233 |\n",
            "|    clip_fraction        | 0.000391     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0476       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.796        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000442    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.25         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 331           |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 105           |\n",
            "|    total_timesteps      | 34816         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021833222 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.013         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.53          |\n",
            "|    n_updates            | 160           |\n",
            "|    policy_gradient_loss | -0.000591     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 3.76          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.53e+05     |\n",
            "|    total_cost           | 2.38e+03     |\n",
            "|    total_reward         | 3.53e+05     |\n",
            "|    total_reward_pct     | 353          |\n",
            "|    total_trades         | 2493         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025727812 |\n",
            "|    clip_fraction        | 0.000928     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.157        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.398        |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.48e+05     |\n",
            "|    total_cost           | 2.82e+03     |\n",
            "|    total_reward         | 3.48e+05     |\n",
            "|    total_reward_pct     | 348          |\n",
            "|    total_trades         | 2484         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 117          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028410442 |\n",
            "|    clip_fraction        | 0.00537      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0754       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.46         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.000919    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.04         |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 50\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 435011.81\n",
            "total_reward: 335011.81\n",
            "total_cost: 2617.04\n",
            "total_trades: 2499\n",
            "Sharpe: 0.772\n",
            "=================================\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.35e+05     |\n",
            "|    total_cost           | 2.62e+03     |\n",
            "|    total_reward         | 3.35e+05     |\n",
            "|    total_reward_pct     | 335          |\n",
            "|    total_trades         | 2499         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041718455 |\n",
            "|    clip_fraction        | 0.00205      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.092        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.619        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.52e+05     |\n",
            "|    total_cost           | 2.58e+03     |\n",
            "|    total_reward         | 3.52e+05     |\n",
            "|    total_reward_pct     | 352          |\n",
            "|    total_trades         | 2497         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 130          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015601624 |\n",
            "|    clip_fraction        | 0.00254      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0974       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.9          |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000719    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 2.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 136          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044141533 |\n",
            "|    clip_fraction        | 0.00229      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0646       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.951        |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 2.45         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.28e+05     |\n",
            "|    total_cost           | 2.27e+03     |\n",
            "|    total_reward         | 3.28e+05     |\n",
            "|    total_reward_pct     | 328          |\n",
            "|    total_trades         | 2488         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048352284 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.148        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.39         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 1.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.62e+05     |\n",
            "|    total_cost           | 2.03e+03     |\n",
            "|    total_reward         | 4.62e+05     |\n",
            "|    total_reward_pct     | 462          |\n",
            "|    total_trades         | 2495         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 148          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002885577 |\n",
            "|    clip_fraction        | 0.00186      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0692       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.956        |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.000594    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 2.38         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.65e+05     |\n",
            "|    total_cost           | 2.26e+03     |\n",
            "|    total_reward         | 3.65e+05     |\n",
            "|    total_reward_pct     | 365          |\n",
            "|    total_trades         | 2495         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019252774 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0709       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.962        |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 3.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.04e+05     |\n",
            "|    total_cost           | 2.55e+03     |\n",
            "|    total_reward         | 4.04e+05     |\n",
            "|    total_reward_pct     | 404          |\n",
            "|    total_trades         | 2500         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 329          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 161          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037876833 |\n",
            "|    clip_fraction        | 0.0162       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0986       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.756        |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 2.28         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 330         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007284002 |\n",
            "|    clip_fraction        | 0.0193      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.042       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1.46        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00222    |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 2.94        |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| environment/            |                |\n",
            "|    portfolio_value      | 6.02e+05       |\n",
            "|    total_cost           | 2.64e+03       |\n",
            "|    total_reward         | 5.02e+05       |\n",
            "|    total_reward_pct     | 502            |\n",
            "|    total_trades         | 2498           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 330            |\n",
            "|    iterations           | 28             |\n",
            "|    time_elapsed         | 173            |\n",
            "|    total_timesteps      | 57344          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -0.00032773177 |\n",
            "|    clip_fraction        | 0.0216         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.41          |\n",
            "|    explained_variance   | -0.00531       |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 1.39           |\n",
            "|    n_updates            | 270            |\n",
            "|    policy_gradient_loss | -0.00156       |\n",
            "|    std                  | 0.994          |\n",
            "|    value_loss           | 2.83           |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 5.22e+05      |\n",
            "|    total_cost           | 2.42e+03      |\n",
            "|    total_reward         | 4.22e+05      |\n",
            "|    total_reward_pct     | 422           |\n",
            "|    total_trades         | 2489          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 330           |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 179           |\n",
            "|    total_timesteps      | 59392         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -0.0012472512 |\n",
            "|    clip_fraction        | 0.00186       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 0.0718        |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.26          |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -0.000627     |\n",
            "|    std                  | 0.997         |\n",
            "|    value_loss           | 2.48          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.07e+05     |\n",
            "|    total_cost           | 2.33e+03     |\n",
            "|    total_reward         | 5.07e+05     |\n",
            "|    total_reward_pct     | 507          |\n",
            "|    total_trades         | 2491         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054165223 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.0625       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.52         |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.92         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| environment/            |            |\n",
            "|    portfolio_value      | 5.2e+05    |\n",
            "|    total_cost           | 2.11e+03   |\n",
            "|    total_reward         | 4.2e+05    |\n",
            "|    total_reward_pct     | 420        |\n",
            "|    total_trades         | 2491       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 330        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 192        |\n",
            "|    total_timesteps      | 63488      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00834247 |\n",
            "|    clip_fraction        | 0.0399     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.42      |\n",
            "|    explained_variance   | 0.0525     |\n",
            "|    learning_rate        | 0.0001     |\n",
            "|    loss                 | 2.54       |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.00483   |\n",
            "|    std                  | 0.999      |\n",
            "|    value_loss           | 3.96       |\n",
            "----------------------------------------\n",
            "day: 2515, episode: 60\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 629880.66\n",
            "total_reward: 529880.66\n",
            "total_cost: 1896.40\n",
            "total_trades: 2500\n",
            "Sharpe: 0.896\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 6.3e+05       |\n",
            "|    total_cost           | 1.9e+03       |\n",
            "|    total_reward         | 5.3e+05       |\n",
            "|    total_reward_pct     | 530           |\n",
            "|    total_trades         | 2500          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 330           |\n",
            "|    iterations           | 32            |\n",
            "|    time_elapsed         | 198           |\n",
            "|    total_timesteps      | 65536         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00039811086 |\n",
            "|    clip_fraction        | 0.0042        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0.063         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.6           |\n",
            "|    n_updates            | 310           |\n",
            "|    policy_gradient_loss | -0.000223     |\n",
            "|    std                  | 0.999         |\n",
            "|    value_loss           | 2.95          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 330         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006055448 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.0398      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.02        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00277    |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 4.75        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.53e+05     |\n",
            "|    total_cost           | 1.68e+03     |\n",
            "|    total_reward         | 4.53e+05     |\n",
            "|    total_reward_pct     | 453          |\n",
            "|    total_trades         | 2491         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 210          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007960226 |\n",
            "|    clip_fraction        | 0.00303      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.751        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000331    |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 1.62         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 6.2e+05     |\n",
            "|    total_cost           | 1.65e+03    |\n",
            "|    total_reward         | 5.2e+05     |\n",
            "|    total_reward_pct     | 520         |\n",
            "|    total_trades         | 2494        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 330         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003627055 |\n",
            "|    clip_fraction        | 0.0127      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.0773      |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.88        |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.000963   |\n",
            "|    std                  | 0.995       |\n",
            "|    value_loss           | 3.31        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6e+05        |\n",
            "|    total_cost           | 1.77e+03     |\n",
            "|    total_reward         | 5e+05        |\n",
            "|    total_reward_pct     | 500          |\n",
            "|    total_trades         | 2499         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 223          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011457319 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0425       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.57         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 4.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.01e+05     |\n",
            "|    total_cost           | 1.97e+03     |\n",
            "|    total_reward         | 5.01e+05     |\n",
            "|    total_reward_pct     | 501          |\n",
            "|    total_trades         | 2500         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 229          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021304304 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0516       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.24         |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 3.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 235          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020342357 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.0391       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.94         |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    std                  | 0.985        |\n",
            "|    value_loss           | 4.37         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.27e+05     |\n",
            "|    total_cost           | 2.09e+03     |\n",
            "|    total_reward         | 5.27e+05     |\n",
            "|    total_reward_pct     | 527          |\n",
            "|    total_trades         | 2497         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004429808 |\n",
            "|    clip_fraction        | 0.00166      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | -0.00633     |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.29         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.000214    |\n",
            "|    std                  | 0.985        |\n",
            "|    value_loss           | 2.49         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 6.21e+05     |\n",
            "|    total_cost           | 1.92e+03     |\n",
            "|    total_reward         | 5.21e+05     |\n",
            "|    total_reward_pct     | 521          |\n",
            "|    total_trades         | 2499         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 247          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002485596 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0282       |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.25         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    std                  | 0.984        |\n",
            "|    value_loss           | 3.82         |\n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fwLOGD0kYX"
      },
      "source": [
        "## TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ElntVCrq2-",
        "outputId": "b9d42e6a-2a66-444f-c556-c3e78fee76d4"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 128, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.0003}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl2tYmwyruVi",
        "outputId": "eaf8cd89-ccbf-4d67-e835-f9bf6a50fd4b"
      },
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/td3/td3_1\n",
            "day: 2515, episode: 70\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 125      |\n",
            "|    time_elapsed     | 79       |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 2.62e+03 |\n",
            "|    critic_loss      | 1.44e+04 |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 7548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 111      |\n",
            "|    time_elapsed     | 180      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 2.04e+03 |\n",
            "|    critic_loss      | 5.08e+03 |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 17612    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 107      |\n",
            "|    time_elapsed     | 280      |\n",
            "|    total timesteps  | 30192    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 1.57e+03 |\n",
            "|    critic_loss      | 2.27e+03 |\n",
            "|    learning_rate    | 0.0003   |\n",
            "|    n_updates        | 27676    |\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLfiknV90ojP"
      },
      "source": [
        "## SAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aheRRAnryLM",
        "outputId": "c6e704f2-b82a-4b93-8a3f-107fc08c39e7"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.00003,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 3e-05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN_hr4Ysr16C",
        "outputId": "cc24dbd7-9e72-46f2-ab12-2afdde2418f9"
      },
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/sac/sac_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 60       |\n",
            "|    time_elapsed     | 167      |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 317      |\n",
            "|    critic_loss      | 58.4     |\n",
            "|    ent_coef         | 0.135    |\n",
            "|    ent_coef_loss    | 18.7     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 9963     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 60       |\n",
            "|    time_elapsed     | 335      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 264      |\n",
            "|    critic_loss      | 1.86     |\n",
            "|    ent_coef         | 0.182    |\n",
            "|    ent_coef_loss    | 15.9     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 20027    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 90\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWyoGgzjEYiu"
      },
      "source": [
        "## aaa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msYBglNU0tcf"
      },
      "source": [
        "#from finrl.trade.backtest import backtest_stats, baseline_stats, backtest_plot"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAaAwPV90yRa"
      },
      "source": [
        "from finrl.trade.backtest import backtest_stats"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMuQRHCU0zq8"
      },
      "source": [
        "from finrl.trade.backtest import backtest_plot"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "gdF94oka1DpC",
        "outputId": "872dd029-cd27-43b7-cb84-a9c5ab0a2f6a"
      },
      "source": [
        "trade.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>38.722500</td>\n",
              "      <td>39.712502</td>\n",
              "      <td>38.557499</td>\n",
              "      <td>38.505024</td>\n",
              "      <td>148158800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.016889</td>\n",
              "      <td>44.505522</td>\n",
              "      <td>35.444587</td>\n",
              "      <td>37.867340</td>\n",
              "      <td>-91.571542</td>\n",
              "      <td>42.250808</td>\n",
              "      <td>41.225720</td>\n",
              "      <td>46.488189</td>\n",
              "      <td>26.255061</td>\n",
              "      <td>39.177500</td>\n",
              "      <td>39.975055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.517199</td>\n",
              "      <td>-6.875741</td>\n",
              "      <td>-0.761653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>35.994999</td>\n",
              "      <td>36.430000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>34.669640</td>\n",
              "      <td>365248800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.199742</td>\n",
              "      <td>43.911981</td>\n",
              "      <td>34.998697</td>\n",
              "      <td>32.751902</td>\n",
              "      <td>-177.958729</td>\n",
              "      <td>55.246973</td>\n",
              "      <td>40.808453</td>\n",
              "      <td>46.157722</td>\n",
              "      <td>11.997918</td>\n",
              "      <td>37.358749</td>\n",
              "      <td>39.455339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.050853</td>\n",
              "      <td>-7.085639</td>\n",
              "      <td>-0.763467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>36.132500</td>\n",
              "      <td>37.137501</td>\n",
              "      <td>35.950001</td>\n",
              "      <td>36.149662</td>\n",
              "      <td>234428400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.199870</td>\n",
              "      <td>43.454764</td>\n",
              "      <td>34.762716</td>\n",
              "      <td>36.192789</td>\n",
              "      <td>-139.717644</td>\n",
              "      <td>47.060632</td>\n",
              "      <td>40.502857</td>\n",
              "      <td>45.854029</td>\n",
              "      <td>12.988335</td>\n",
              "      <td>36.063749</td>\n",
              "      <td>39.108740</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.077832</td>\n",
              "      <td>-7.044321</td>\n",
              "      <td>-0.766086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>37.174999</td>\n",
              "      <td>37.207500</td>\n",
              "      <td>36.474998</td>\n",
              "      <td>36.069202</td>\n",
              "      <td>219111200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.181318</td>\n",
              "      <td>43.003009</td>\n",
              "      <td>34.561260</td>\n",
              "      <td>36.088942</td>\n",
              "      <td>-122.742724</td>\n",
              "      <td>46.245025</td>\n",
              "      <td>40.266752</td>\n",
              "      <td>45.536440</td>\n",
              "      <td>13.030644</td>\n",
              "      <td>36.653749</td>\n",
              "      <td>38.782134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.884737</td>\n",
              "      <td>-6.900339</td>\n",
              "      <td>-0.767321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>37.389999</td>\n",
              "      <td>37.955002</td>\n",
              "      <td>37.130001</td>\n",
              "      <td>36.756794</td>\n",
              "      <td>164101200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.087075</td>\n",
              "      <td>42.733426</td>\n",
              "      <td>34.398295</td>\n",
              "      <td>37.670002</td>\n",
              "      <td>-95.013556</td>\n",
              "      <td>37.537680</td>\n",
              "      <td>40.055192</td>\n",
              "      <td>45.272874</td>\n",
              "      <td>18.339891</td>\n",
              "      <td>37.282499</td>\n",
              "      <td>38.565861</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.041614</td>\n",
              "      <td>-6.589742</td>\n",
              "      <td>-0.759067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high  ...       wr_10       dma      trix\n",
              "0  2019-01-02  38.722500  39.712502  ...   64.517199 -6.875741 -0.761653\n",
              "1  2019-01-03  35.994999  36.430000  ...  113.050853 -7.085639 -0.763467\n",
              "2  2019-01-04  36.132500  37.137501  ...   87.077832 -7.044321 -0.766086\n",
              "3  2019-01-07  37.174999  37.207500  ...   86.884737 -6.900339 -0.767321\n",
              "4  2019-01-08  37.389999  37.955002  ...   71.041614 -6.589742 -0.759067\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yer7WCBW2OdO"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UTq4DWoRZ04"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w44KdOhfGNWg",
        "outputId": "972b131a-ad55-4c5b-c42e-02a2dbd67f8c"
      },
      "source": [
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_a2c, environment= e_trade_gym)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhBUD-xsGSUA",
        "outputId": "2e65f218-5a65-4868-c5ee-e12d7eb4217c"
      },
      "source": [
        "print(\"==============Results_A2C===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value= df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Results_A2C===========\n",
            "Annual return          0.802528\n",
            "Cumulative returns     2.256713\n",
            "Annual volatility      0.349486\n",
            "Sharpe ratio           1.865634\n",
            "Calmar ratio           2.706133\n",
            "Stability              0.938914\n",
            "Max drawdown          -0.296559\n",
            "Omega ratio            1.423152\n",
            "Sortino ratio          2.829397\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.116030\n",
            "Daily value at risk   -0.041444\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaKfq653FTYm"
      },
      "source": [
        "### DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s65tG8yzDDNg",
        "outputId": "eea80476-8357-40c7-c32e-da05979eeeac"
      },
      "source": [
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_ddpg, environment= e_trade_gym)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUJWicisDTq6"
      },
      "source": [
        "from finrl.trade.backtest import backtest_stats, backtest_plot"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI_PHcRqDVns",
        "outputId": "fec742ac-1c8d-4745-ad36-af332d417d60"
      },
      "source": [
        "print(\"==============Results_DDPG===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value= df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Results_DDPG===========\n",
            "Annual return          0.854155\n",
            "Cumulative returns     2.446326\n",
            "Annual volatility      0.366768\n",
            "Sharpe ratio           1.872040\n",
            "Calmar ratio           2.718149\n",
            "Stability              0.938197\n",
            "Max drawdown          -0.314242\n",
            "Omega ratio            1.425131\n",
            "Sortino ratio          2.833244\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.101082\n",
            "Daily value at risk   -0.043484\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLgZ33eA1FaV"
      },
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt2PKihpReLN"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcx2YBc7F_vM",
        "outputId": "2770f295-ea14-42cc-d514-1107ddd950b4"
      },
      "source": [
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_ppo, environment= e_trade_gym)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNecfE3AGfZx",
        "outputId": "15b844c2-ef70-4838-c369-de790b769522"
      },
      "source": [
        "print(\"==============Results_PPO===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value= df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Results_PPO===========\n",
            "Annual return          0.784683\n",
            "Cumulative returns     2.192425\n",
            "Annual volatility      0.356959\n",
            "Sharpe ratio           1.806201\n",
            "Calmar ratio           2.569584\n",
            "Stability              0.936927\n",
            "Max drawdown          -0.305374\n",
            "Omega ratio            1.412866\n",
            "Sortino ratio          2.718912\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.094497\n",
            "Daily value at risk   -0.042414\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3nkyRriRiN9"
      },
      "source": [
        "### TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5KvO6D4GEgM",
        "outputId": "8a752194-2fc9-4f76-8297-00d74e7cd226"
      },
      "source": [
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_td3, environment= e_trade_gym)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvV71ZQSGgTo",
        "outputId": "ae37c009-9882-4aac-82a9-6d1df2667302"
      },
      "source": [
        "print(\"==============Results_TD3===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value= df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Results_TD3===========\n",
            "Annual return          0.0\n",
            "Cumulative returns     0.0\n",
            "Annual volatility      0.0\n",
            "Sharpe ratio           NaN\n",
            "Calmar ratio           NaN\n",
            "Stability              0.0\n",
            "Max drawdown           0.0\n",
            "Omega ratio            NaN\n",
            "Sortino ratio          NaN\n",
            "Skew                   NaN\n",
            "Kurtosis               NaN\n",
            "Tail ratio             NaN\n",
            "Daily value at risk    0.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt5_A91CRkm9"
      },
      "source": [
        "### SAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tKhV-BRGITh",
        "outputId": "bb09d688-dcc8-4136-ea3e-48f36c9287b8"
      },
      "source": [
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=model_sac, environment= e_trade_gym)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0yeGVdtGhLt",
        "outputId": "32f53957-a967-46ba-c0ef-e8d9641c6954"
      },
      "source": [
        "print(\"==============Results_SAC===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value= df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Results_SAC===========\n",
            "Annual return          0.0\n",
            "Cumulative returns     0.0\n",
            "Annual volatility      0.0\n",
            "Sharpe ratio           NaN\n",
            "Calmar ratio           NaN\n",
            "Stability              0.0\n",
            "Max drawdown           0.0\n",
            "Omega ratio            NaN\n",
            "Sortino ratio          NaN\n",
            "Skew                   NaN\n",
            "Kurtosis               NaN\n",
            "Tail ratio             NaN\n",
            "Daily value at risk    0.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}